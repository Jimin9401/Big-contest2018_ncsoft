{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#패키지 불러오기\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "from random import *\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length\n",
    "def last_relevant(output, length):\n",
    "    batch_size = tf.shape(output)[0]\n",
    "    max_length = tf.shape(output)[1]\n",
    "    out_size = int(output.get_shape()[2])\n",
    "    index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "    flat = tf.reshape(output, [-1, out_size])\n",
    "    relevant = tf.gather(flat, index)\n",
    "    return relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 저장\n",
    "#np.save('input.npy',input_array)\n",
    "#np.save('target.npy',target)\n",
    "\n",
    "input_array=np.load('train_input_2.npy')\n",
    "target=np.load('train_lab_2.npy')\n",
    "\n",
    "val_input=np.load('val_input_2.npy')\n",
    "val_lab=np.load('val_lab_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 8, 36)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "input_size = input_array.shape[2]\n",
    "hidden_size = 100  # RNN hidden size\n",
    "output_dim = 36  # final output size (RNN or softmax, etc.)\n",
    "total_batch = input_array.shape[0]\n",
    "batch_size = int(input_array.shape[0]/10)  # one sample data, one batch\n",
    "sequence_length = input_array.shape[1]-1  # number of lstm unfolding (unit #)\n",
    "epochs= 100000\n",
    "lr=0.0001\n",
    "acc_batch_size=int(input_array.shape[0])\n",
    "val_batch_size=int(val_input.shape[0])\n",
    "num_class=4\n",
    "keep_prob=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    " def get_a_cell(hidden_size, keep_prob):\n",
    "            lstm = tf.contrib.rnn.LSTMCell(num_units=hidden_size,initializer=tf.contrib.layers.xavier_initializer())\n",
    "            drop = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return drop\n",
    "        \n",
    "with tf.name_scope('lstm'):\n",
    "     cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "     [get_a_cell(hidden_size, keep_prob) for _ in range(3)]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-7c917784cac3>:46: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "#데이터를 담을 placeholder X, label을 담을 placeholder Y를 생성\n",
    "X=tf.placeholder(tf.float32,[None,sequence_length+1,input_size])\n",
    "Y=tf.placeholder(tf.int64,[None,1])\n",
    "\n",
    "Y_one_hot = tf.one_hot(Y, num_class)  \n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, num_class])\n",
    "\n",
    "\n",
    "#마지막 fully connected layer에서 쓸 weight과 bias 정함\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([hidden_size, num_class]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_class]))\n",
    "}\n",
    "\n",
    "\n",
    "#lstm을 돌리고 output과 state을 받음\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, sequence_length=length(X), dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "#input데이터의 length, 몇번째 output의 값을 다음 layer로 넘겨줄지를 저장함\n",
    "aa=length(X)\n",
    "last = last_relevant(outputs,aa)\n",
    "\n",
    "#마지막 output을 이용해서 prediction, sigmoid 전값을 확인할 수도 있어 일단 따로지정함\n",
    "softmaxed = tf.nn.softmax(tf.matmul(last,weights['out'])+biases['out'])\n",
    "\n",
    "\n",
    "\n",
    "#confusion_matrix\n",
    "confusion_matrix=tf.confusion_matrix(tf.reshape(softmaxed,[-1]), tf.reshape(Y_one_hot,[-1]))\n",
    "\n",
    "#prediction, accuracy\n",
    "prediction = tf.argmax(softmaxed, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#이탈 유지 여부를 얼마나 맞췄나\n",
    "binary_acc=tf.reduce_mean(tf.cast((tf.equal((tf.argmax(Y_one_hot, 1)>0),(prediction>0))), tf.float32))\n",
    "#loss function\n",
    "\n",
    "loss_i = tf.nn.softmax_cross_entropy_with_logits(logits=softmaxed, \n",
    "\n",
    "                                                 labels=Y_one_hot)\n",
    "\n",
    "loss = tf.reduce_mean(loss_i)\n",
    "\n",
    "\n",
    "#train 함수\n",
    "train = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/tensorflow/issues/14897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cd5147aab4b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "sess.run(Y_one_hot,feed_dict={Y:target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5085695 , 0.01712617, 0.45148635, 0.022818  ],\n",
       "       [0.6452974 , 0.02595782, 0.29897824, 0.02976653],\n",
       "       [0.641308  , 0.02164564, 0.30146024, 0.03558607],\n",
       "       ...,\n",
       "       [0.7277875 , 0.02510558, 0.22091077, 0.02619619],\n",
       "       [0.5090416 , 0.01728246, 0.45077604, 0.02289989],\n",
       "       [0.5381513 , 0.01823085, 0.419098  , 0.02451983]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(softmaxed,feed_dict={X:input_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4248296215337289677]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gpu가 사용 가능한지 체크\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess= tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch별 accuracy, specificity, sensitivity, precision, validation accuracy을 저장할 list를 만듦\n",
    "total_acc=[]\n",
    "total_sp=[]\n",
    "total_se=[]\n",
    "total_pr=[]\n",
    "total_val_acc=[]\n",
    "total_val_b_acc=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0   cost :  1.311037003993988   accuracy :  0.43220001459121704 val_acc:  0.42669999599456787 val_binary_acc 0.7882999777793884\n",
      "epoch :  1   cost :  1.26708265542984   accuracy :  0.5188999772071838 val_acc:  0.517799973487854 val_binary_acc 0.8076000213623047\n",
      "epoch :  2   cost :  1.2352174043655393   accuracy :  0.538777768611908 val_acc:  0.5397999882698059 val_binary_acc 0.8052999973297119\n",
      "epoch :  3   cost :  1.197083306312561   accuracy :  0.5040555596351624 val_acc:  0.5015000104904175 val_binary_acc 0.8346999883651733\n",
      "epoch :  4   cost :  1.1686894059181212   accuracy :  0.5692444443702698 val_acc:  0.5705000162124634 val_binary_acc 0.8345000147819519\n",
      "epoch :  5   cost :  1.1616035223007202   accuracy :  0.567455530166626 val_acc:  0.5724999904632568 val_binary_acc 0.8355000019073486\n",
      "epoch :  6   cost :  1.1490442276000976   accuracy :  0.5904555320739746 val_acc:  0.5928000211715698 val_binary_acc 0.8452000021934509\n",
      "epoch :  7   cost :  1.1389972686767578   accuracy :  0.5994222164154053 val_acc:  0.6028000116348267 val_binary_acc 0.8465999960899353\n",
      "epoch :  8   cost :  1.131980085372925   accuracy :  0.5940889120101929 val_acc:  0.5947999954223633 val_binary_acc 0.8456000089645386\n",
      "epoch :  9   cost :  1.1282480239868165   accuracy :  0.5981888771057129 val_acc:  0.6015999913215637 val_binary_acc 0.8490999937057495\n",
      "epoch :  10   cost :  1.1213014364242553   accuracy :  0.6221555471420288 val_acc:  0.626800000667572 val_binary_acc 0.8453999757766724\n",
      "epoch :  11   cost :  1.1167020082473755   accuracy :  0.6242111325263977 val_acc:  0.6288999915122986 val_binary_acc 0.8517000079154968\n",
      "epoch :  12   cost :  1.1149949193000792   accuracy :  0.6262000203132629 val_acc:  0.6295999884605408 val_binary_acc 0.8535000085830688\n",
      "epoch :  13   cost :  1.1207582831382752   accuracy :  0.6198555827140808 val_acc:  0.6245999932289124 val_binary_acc 0.8363000154495239\n",
      "epoch :  23   cost :  1.1045416474342347   accuracy :  0.63108891248703 val_acc:  0.6362000107765198 val_binary_acc 0.8503999710083008\n",
      "epoch :  24   cost :  1.1044365406036378   accuracy :  0.635699987411499 val_acc:  0.6381999850273132 val_binary_acc 0.8590999841690063\n",
      "epoch :  25   cost :  1.102748656272888   accuracy :  0.6366111040115356 val_acc:  0.63919997215271 val_binary_acc 0.8619999885559082\n",
      "epoch :  26   cost :  1.099593162536621   accuracy :  0.6341444253921509 val_acc:  0.6378999948501587 val_binary_acc 0.8546000123023987\n",
      "epoch :  27   cost :  1.0997620940208435   accuracy :  0.638022243976593 val_acc:  0.6409000158309937 val_binary_acc 0.8604999780654907\n",
      "epoch :  28   cost :  1.0984761595726011   accuracy :  0.6388999819755554 val_acc:  0.6406000256538391 val_binary_acc 0.8640000224113464\n",
      "epoch :  29   cost :  1.0974498748779296   accuracy :  0.6351222395896912 val_acc:  0.6366000175476074 val_binary_acc 0.8601999878883362\n",
      "epoch :  30   cost :  1.101558518409729   accuracy :  0.6337666511535645 val_acc:  0.6366999745368958 val_binary_acc 0.8593000173568726\n",
      "epoch :  31   cost :  1.1005183100700378   accuracy :  0.6386666893959045 val_acc:  0.6399000287055969 val_binary_acc 0.8601999878883362\n",
      "epoch :  32   cost :  1.0972221136093139   accuracy :  0.6395221948623657 val_acc:  0.6424000263214111 val_binary_acc 0.8598999977111816\n",
      "epoch :  33   cost :  1.0956525444984435   accuracy :  0.6396555304527283 val_acc:  0.6444000005722046 val_binary_acc 0.857699990272522\n",
      "epoch :  34   cost :  1.0963278412818909   accuracy :  0.6410444378852844 val_acc:  0.6428999900817871 val_binary_acc 0.8623999953269958\n",
      "epoch :  35   cost :  1.0946585655212402   accuracy :  0.6404444575309753 val_acc:  0.6407999992370605 val_binary_acc 0.8634999990463257\n",
      "epoch :  36   cost :  1.0929881453514099   accuracy :  0.6436333060264587 val_acc:  0.6460999846458435 val_binary_acc 0.8639000058174133\n",
      "epoch :  37   cost :  1.0937103271484374   accuracy :  0.6416000127792358 val_acc:  0.6442000269889832 val_binary_acc 0.8633000254631042\n",
      "epoch :  38   cost :  1.093166434764862   accuracy :  0.6442777514457703 val_acc:  0.6470999717712402 val_binary_acc 0.8652999997138977\n",
      "epoch :  39   cost :  1.0925367832183839   accuracy :  0.642799973487854 val_acc:  0.6448000073432922 val_binary_acc 0.8651000261306763\n",
      "epoch :  40   cost :  1.0922799944877624   accuracy :  0.6432111263275146 val_acc:  0.64410001039505 val_binary_acc 0.8669000267982483\n",
      "epoch :  41   cost :  1.0916514992713928   accuracy :  0.6419888734817505 val_acc:  0.6442000269889832 val_binary_acc 0.8659999966621399\n",
      "epoch :  42   cost :  1.0913492560386657   accuracy :  0.6449999809265137 val_acc:  0.6467999815940857 val_binary_acc 0.8679999709129333\n",
      "epoch :  43   cost :  1.0908220887184144   accuracy :  0.6427555680274963 val_acc:  0.6439999938011169 val_binary_acc 0.8640000224113464\n",
      "epoch :  44   cost :  1.0905233383178712   accuracy :  0.6416222453117371 val_acc:  0.6431999802589417 val_binary_acc 0.8657000064849854\n",
      "epoch :  45   cost :  1.090971326828003   accuracy :  0.6422333121299744 val_acc:  0.64410001039505 val_binary_acc 0.8634999990463257\n",
      "epoch :  46   cost :  1.0904627084732055   accuracy :  0.6423666477203369 val_acc:  0.6438000202178955 val_binary_acc 0.8644999861717224\n",
      "epoch :  47   cost :  1.090683662891388   accuracy :  0.6447222232818604 val_acc:  0.6460000276565552 val_binary_acc 0.8619999885559082\n",
      "epoch :  48   cost :  1.0899905800819398   accuracy :  0.6460000276565552 val_acc:  0.6477000117301941 val_binary_acc 0.864300012588501\n",
      "epoch :  49   cost :  1.0901577353477476   accuracy :  0.641011118888855 val_acc:  0.6421999931335449 val_binary_acc 0.8640999794006348\n",
      "epoch :  50   cost :  1.0911267280578612   accuracy :  0.6446555852890015 val_acc:  0.6474999785423279 val_binary_acc 0.8636999726295471\n",
      "epoch :  51   cost :  1.090368413925171   accuracy :  0.6437666416168213 val_acc:  0.6463000178337097 val_binary_acc 0.8629999756813049\n",
      "epoch :  52   cost :  1.089748179912567   accuracy :  0.6464889049530029 val_acc:  0.6473000049591064 val_binary_acc 0.8651000261306763\n",
      "epoch :  53   cost :  1.0882438540458679   accuracy :  0.6464777588844299 val_acc:  0.6485000252723694 val_binary_acc 0.8647000193595886\n",
      "epoch :  54   cost :  1.087732517719269   accuracy :  0.6452333331108093 val_acc:  0.6474000215530396 val_binary_acc 0.8662999868392944\n",
      "epoch :  55   cost :  1.0884420156478882   accuracy :  0.6460555791854858 val_acc:  0.6466000080108643 val_binary_acc 0.8640000224113464\n",
      "epoch :  56   cost :  1.088114333152771   accuracy :  0.6479777693748474 val_acc:  0.6503000259399414 val_binary_acc 0.8682000041007996\n",
      "epoch :  57   cost :  1.0867539644241333   accuracy :  0.6474111080169678 val_acc:  0.651199996471405 val_binary_acc 0.8657000064849854\n",
      "epoch :  58   cost :  1.0871990203857422   accuracy :  0.6460333466529846 val_acc:  0.6488000154495239 val_binary_acc 0.8657000064849854\n",
      "epoch :  59   cost :  1.0885444521903993   accuracy :  0.6485111117362976 val_acc:  0.6507999897003174 val_binary_acc 0.8634999990463257\n",
      "epoch :  60   cost :  1.0876909971237183   accuracy :  0.6480888724327087 val_acc:  0.6500999927520752 val_binary_acc 0.8658000230789185\n",
      "epoch :  61   cost :  1.0887453436851502   accuracy :  0.6477333307266235 val_acc:  0.6502000093460083 val_binary_acc 0.8676000237464905\n",
      "epoch :  62   cost :  1.0879615426063536   accuracy :  0.6438999772071838 val_acc:  0.6444000005722046 val_binary_acc 0.8662999868392944\n",
      "epoch :  63   cost :  1.0876241207122803   accuracy :  0.6485999822616577 val_acc:  0.651199996471405 val_binary_acc 0.8676999807357788\n",
      "epoch :  64   cost :  1.0861737847328186   accuracy :  0.6496222019195557 val_acc:  0.6520000100135803 val_binary_acc 0.868399977684021\n",
      "epoch :  65   cost :  1.0857388854026793   accuracy :  0.6445778012275696 val_acc:  0.6481000185012817 val_binary_acc 0.8655999898910522\n",
      "epoch :  66   cost :  1.0864446878433227   accuracy :  0.6504111289978027 val_acc:  0.652400016784668 val_binary_acc 0.8676000237464905\n",
      "epoch :  67   cost :  1.0869603395462037   accuracy :  0.6383110880851746 val_acc:  0.6410999894142151 val_binary_acc 0.852400004863739\n",
      "epoch :  68   cost :  1.0898289799690248   accuracy :  0.6450777649879456 val_acc:  0.6496999859809875 val_binary_acc 0.8582000136375427\n",
      "epoch :  69   cost :  1.0891826391220092   accuracy :  0.6466777920722961 val_acc:  0.6504999995231628 val_binary_acc 0.8622000217437744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  70   cost :  1.0890072822570802   accuracy :  0.6462888717651367 val_acc:  0.6499999761581421 val_binary_acc 0.8659999966621399\n",
      "epoch :  71   cost :  1.0857437133789065   accuracy :  0.6373222470283508 val_acc:  0.6317999958992004 val_binary_acc 0.864799976348877\n",
      "epoch :  72   cost :  1.0846165776252747   accuracy :  0.649399995803833 val_acc:  0.6517999768257141 val_binary_acc 0.8687999844551086\n",
      "epoch :  73   cost :  1.0852741956710814   accuracy :  0.6504555344581604 val_acc:  0.6538000106811523 val_binary_acc 0.8689000010490417\n",
      "epoch :  74   cost :  1.084567654132843   accuracy :  0.6512110829353333 val_acc:  0.6549999713897705 val_binary_acc 0.8689000010490417\n",
      "epoch :  75   cost :  1.083283770084381   accuracy :  0.6521000266075134 val_acc:  0.6552000045776367 val_binary_acc 0.8676000237464905\n",
      "epoch :  76   cost :  1.083870780467987   accuracy :  0.6517333388328552 val_acc:  0.6550999879837036 val_binary_acc 0.8687000274658203\n",
      "epoch :  77   cost :  1.0830581784248352   accuracy :  0.6505222320556641 val_acc:  0.6549000144004822 val_binary_acc 0.870199978351593\n",
      "epoch :  78   cost :  1.0830252528190614   accuracy :  0.6520333290100098 val_acc:  0.6559000015258789 val_binary_acc 0.8702999949455261\n",
      "epoch :  79   cost :  1.0823557734489442   accuracy :  0.6533889174461365 val_acc:  0.6571999788284302 val_binary_acc 0.8693000078201294\n",
      "epoch :  80   cost :  1.0823195576667786   accuracy :  0.6532555818557739 val_acc:  0.6581000089645386 val_binary_acc 0.8689000010490417\n",
      "epoch :  81   cost :  1.0818604707717896   accuracy :  0.6532555818557739 val_acc:  0.6577000021934509 val_binary_acc 0.8705999851226807\n",
      "epoch :  82   cost :  1.0840660810470581   accuracy :  0.6530888676643372 val_acc:  0.6567000150680542 val_binary_acc 0.8711000084877014\n",
      "epoch :  83   cost :  1.0827327489852905   accuracy :  0.6527222394943237 val_acc:  0.6567000150680542 val_binary_acc 0.8693000078201294\n",
      "epoch :  84   cost :  1.082317066192627   accuracy :  0.6531999707221985 val_acc:  0.656000018119812 val_binary_acc 0.8675000071525574\n",
      "epoch :  85   cost :  1.0819803118705749   accuracy :  0.6523777842521667 val_acc:  0.6550999879837036 val_binary_acc 0.8673999905586243\n",
      "epoch :  86   cost :  1.081804883480072   accuracy :  0.6527000069618225 val_acc:  0.6535999774932861 val_binary_acc 0.8694000244140625\n",
      "epoch :  87   cost :  1.0809787273406983   accuracy :  0.6547889113426208 val_acc:  0.6585000157356262 val_binary_acc 0.8705999851226807\n",
      "epoch :  88   cost :  1.0805425882339477   accuracy :  0.6544444561004639 val_acc:  0.6564000248908997 val_binary_acc 0.8671000003814697\n",
      "epoch :  89   cost :  1.0800275087356568   accuracy :  0.654699981212616 val_acc:  0.6588000059127808 val_binary_acc 0.8673999905586243\n",
      "epoch :  90   cost :  1.0828750610351563   accuracy :  0.647422194480896 val_acc:  0.6538000106811523 val_binary_acc 0.8557000160217285\n",
      "epoch :  91   cost :  1.0815712928771972   accuracy :  0.6569888591766357 val_acc:  0.6593000292778015 val_binary_acc 0.8658000230789185\n",
      "epoch :  92   cost :  1.0783322930335997   accuracy :  0.6560666561126709 val_acc:  0.6567999720573425 val_binary_acc 0.8676999807357788\n",
      "epoch :  93   cost :  1.076505184173584   accuracy :  0.657622218132019 val_acc:  0.6607999801635742 val_binary_acc 0.8712999820709229\n",
      "epoch :  94   cost :  1.0748569250106812   accuracy :  0.6633333563804626 val_acc:  0.6672999858856201 val_binary_acc 0.8658999800682068\n",
      "epoch :  95   cost :  1.0728008151054382   accuracy :  0.6576666831970215 val_acc:  0.6506999731063843 val_binary_acc 0.8672000169754028\n",
      "epoch :  96   cost :  1.0718187689781191   accuracy :  0.6665444374084473 val_acc:  0.6685000061988831 val_binary_acc 0.869700014591217\n",
      "epoch :  97   cost :  1.0707245945930481   accuracy :  0.6654999852180481 val_acc:  0.6693000197410583 val_binary_acc 0.8683000206947327\n",
      "epoch :  98   cost :  1.0698609471321108   accuracy :  0.6655111312866211 val_acc:  0.6682999730110168 val_binary_acc 0.8711000084877014\n",
      "epoch :  99   cost :  1.0690580010414124   accuracy :  0.6691444516181946 val_acc:  0.6718999743461609 val_binary_acc 0.871399998664856\n",
      "epoch :  100   cost :  1.0691702961921692   accuracy :  0.669011116027832 val_acc:  0.669700026512146 val_binary_acc 0.8689000010490417\n",
      "epoch :  101   cost :  1.0681036710739136   accuracy :  0.6697666645050049 val_acc:  0.6723999977111816 val_binary_acc 0.8691999912261963\n",
      "epoch :  102   cost :  1.067406177520752   accuracy :  0.6692110896110535 val_acc:  0.6714000105857849 val_binary_acc 0.8694999814033508\n",
      "epoch :  103   cost :  1.0674124240875242   accuracy :  0.6696555614471436 val_acc:  0.6725999712944031 val_binary_acc 0.8718000054359436\n",
      "epoch :  104   cost :  1.0669265389442444   accuracy :  0.6690333485603333 val_acc:  0.6715999841690063 val_binary_acc 0.8689000010490417\n",
      "epoch :  105   cost :  1.067830455303192   accuracy :  0.6706444621086121 val_acc:  0.6730999946594238 val_binary_acc 0.8687999844551086\n",
      "epoch :  106   cost :  1.066366410255432   accuracy :  0.670544445514679 val_acc:  0.671999990940094 val_binary_acc 0.8698999881744385\n",
      "epoch :  107   cost :  1.0669946432113646   accuracy :  0.6698444485664368 val_acc:  0.6718000173568726 val_binary_acc 0.8709999918937683\n",
      "epoch :  108   cost :  1.0664111852645874   accuracy :  0.6693000197410583 val_acc:  0.6718999743461609 val_binary_acc 0.8711000084877014\n",
      "epoch :  109   cost :  1.065804123878479   accuracy :  0.6710666418075562 val_acc:  0.6726999878883362 val_binary_acc 0.8664000034332275\n",
      "epoch :  110   cost :  1.0660350561141967   accuracy :  0.6689000129699707 val_acc:  0.6705999970436096 val_binary_acc 0.8708000183105469\n",
      "epoch :  111   cost :  1.06587975025177   accuracy :  0.6720222234725952 val_acc:  0.6740999817848206 val_binary_acc 0.873199999332428\n",
      "epoch :  112   cost :  1.0657427668571473   accuracy :  0.6676999926567078 val_acc:  0.6646000146865845 val_binary_acc 0.8708999752998352\n",
      "epoch :  113   cost :  1.0654292821884155   accuracy :  0.6711778044700623 val_acc:  0.6697999835014343 val_binary_acc 0.8718000054359436\n",
      "epoch :  114   cost :  1.0647828817367553   accuracy :  0.6739444732666016 val_acc:  0.6761000156402588 val_binary_acc 0.8734999895095825\n",
      "epoch :  115   cost :  1.0644452929496766   accuracy :  0.6723333597183228 val_acc:  0.6751000285148621 val_binary_acc 0.8694999814033508\n",
      "epoch :  116   cost :  1.0630621433258058   accuracy :  0.6743666529655457 val_acc:  0.6751999855041504 val_binary_acc 0.8709999918937683\n",
      "epoch :  117   cost :  1.064141356945038   accuracy :  0.6720555424690247 val_acc:  0.6746000051498413 val_binary_acc 0.8683000206947327\n",
      "epoch :  118   cost :  1.0639741539955139   accuracy :  0.6709555387496948 val_acc:  0.6747999787330627 val_binary_acc 0.8676999807357788\n",
      "epoch :  119   cost :  1.063459348678589   accuracy :  0.6726333498954773 val_acc:  0.675599992275238 val_binary_acc 0.8693000078201294\n",
      "epoch :  120   cost :  1.0635626554489135   accuracy :  0.6745555400848389 val_acc:  0.6748999953269958 val_binary_acc 0.8748999834060669\n",
      "epoch :  121   cost :  1.062583041191101   accuracy :  0.6694666743278503 val_acc:  0.6665999889373779 val_binary_acc 0.8716999888420105\n",
      "epoch :  122   cost :  1.062994658946991   accuracy :  0.6746777892112732 val_acc:  0.6765000224113464 val_binary_acc 0.8733999729156494\n",
      "epoch :  123   cost :  1.0631067156791687   accuracy :  0.6733555793762207 val_acc:  0.6746000051498413 val_binary_acc 0.8722000122070312\n",
      "epoch :  124   cost :  1.0632285356521607   accuracy :  0.6740000247955322 val_acc:  0.6743999719619751 val_binary_acc 0.8716999888420105\n",
      "epoch :  125   cost :  1.0629855275154114   accuracy :  0.6744999885559082 val_acc:  0.6762999892234802 val_binary_acc 0.8723999857902527\n",
      "epoch :  126   cost :  1.0623781085014343   accuracy :  0.6755777597427368 val_acc:  0.675599992275238 val_binary_acc 0.8741999864578247\n",
      "epoch :  127   cost :  1.0618722796440123   accuracy :  0.6764000058174133 val_acc:  0.6779000163078308 val_binary_acc 0.8725000023841858\n",
      "epoch :  128   cost :  1.0625046491622925   accuracy :  0.6582666635513306 val_acc:  0.6575999855995178 val_binary_acc 0.8744000196456909\n",
      "epoch :  129   cost :  1.071177852153778   accuracy :  0.6691333055496216 val_acc:  0.6704000234603882 val_binary_acc 0.870199978351593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  130   cost :  1.067293667793274   accuracy :  0.6732110977172852 val_acc:  0.6764000058174133 val_binary_acc 0.8708999752998352\n",
      "epoch :  131   cost :  1.0630350351333617   accuracy :  0.6729555726051331 val_acc:  0.6730999946594238 val_binary_acc 0.8737000226974487\n",
      "epoch :  132   cost :  1.062207567691803   accuracy :  0.6743999719619751 val_acc:  0.6764000058174133 val_binary_acc 0.8744999766349792\n",
      "epoch :  133   cost :  1.0616251230239868   accuracy :  0.6759333610534668 val_acc:  0.6783999800682068 val_binary_acc 0.8726000189781189\n",
      "epoch :  134   cost :  1.061076319217682   accuracy :  0.6770333051681519 val_acc:  0.6775000095367432 val_binary_acc 0.8712999820709229\n",
      "epoch :  135   cost :  1.0599162697792055   accuracy :  0.6759111285209656 val_acc:  0.6776999831199646 val_binary_acc 0.8725000023841858\n",
      "epoch :  136   cost :  1.0603105425834656   accuracy :  0.6772778034210205 val_acc:  0.6794999837875366 val_binary_acc 0.8774999976158142\n",
      "epoch :  137   cost :  1.0599971652030944   accuracy :  0.6762222051620483 val_acc:  0.6751000285148621 val_binary_acc 0.8734999895095825\n",
      "epoch :  138   cost :  1.0597320199012756   accuracy :  0.6780111193656921 val_acc:  0.6809999942779541 val_binary_acc 0.8776999711990356\n",
      "epoch :  139   cost :  1.0595404148101808   accuracy :  0.6756333112716675 val_acc:  0.678600013256073 val_binary_acc 0.8723999857902527\n",
      "epoch :  140   cost :  1.0596528053283694   accuracy :  0.6765444278717041 val_acc:  0.6765000224113464 val_binary_acc 0.8769000172615051\n",
      "epoch :  141   cost :  1.0591938018798828   accuracy :  0.6787222027778625 val_acc:  0.6782000064849854 val_binary_acc 0.8755000233650208\n",
      "epoch :  142   cost :  1.059186041355133   accuracy :  0.678766667842865 val_acc:  0.6789000034332275 val_binary_acc 0.8759999871253967\n",
      "epoch :  143   cost :  1.0586697578430175   accuracy :  0.6782888770103455 val_acc:  0.6776000261306763 val_binary_acc 0.8743000030517578\n",
      "epoch :  144   cost :  1.0589886784553526   accuracy :  0.6788777709007263 val_acc:  0.6820999979972839 val_binary_acc 0.8744999766349792\n",
      "epoch :  145   cost :  1.0582100987434386   accuracy :  0.6792111396789551 val_acc:  0.6798999905586243 val_binary_acc 0.8783000111579895\n",
      "epoch :  146   cost :  1.0586615324020385   accuracy :  0.6783000230789185 val_acc:  0.675599992275238 val_binary_acc 0.8737000226974487\n",
      "epoch :  147   cost :  1.0589632630348207   accuracy :  0.6776444315910339 val_acc:  0.6761000156402588 val_binary_acc 0.8754000067710876\n",
      "epoch :  148   cost :  1.0578772068023683   accuracy :  0.6787333488464355 val_acc:  0.678600013256073 val_binary_acc 0.8748999834060669\n",
      "epoch :  149   cost :  1.0576688528060911   accuracy :  0.6792888641357422 val_acc:  0.6797999739646912 val_binary_acc 0.8752999901771545\n",
      "epoch :  150   cost :  1.0573351502418515   accuracy :  0.6801777482032776 val_acc:  0.6794000267982483 val_binary_acc 0.8758999705314636\n",
      "epoch :  151   cost :  1.057614839076996   accuracy :  0.6792333126068115 val_acc:  0.6794999837875366 val_binary_acc 0.8765000104904175\n",
      "epoch :  152   cost :  1.0579100012779237   accuracy :  0.6788333058357239 val_acc:  0.6790000200271606 val_binary_acc 0.8737000226974487\n",
      "epoch :  153   cost :  1.0569784760475158   accuracy :  0.6810888648033142 val_acc:  0.6805999875068665 val_binary_acc 0.8756999969482422\n",
      "epoch :  154   cost :  1.0562376141548155   accuracy :  0.6804555654525757 val_acc:  0.6787999868392944 val_binary_acc 0.8747000098228455\n",
      "epoch :  155   cost :  1.0559523940086364   accuracy :  0.680744469165802 val_acc:  0.6804999709129333 val_binary_acc 0.8758999705314636\n",
      "epoch :  156   cost :  1.0562454223632813   accuracy :  0.6804222464561462 val_acc:  0.6804999709129333 val_binary_acc 0.8740000128746033\n",
      "epoch :  157   cost :  1.0562079310417176   accuracy :  0.6746110916137695 val_acc:  0.67330002784729 val_binary_acc 0.868399977684021\n",
      "epoch :  158   cost :  1.0583710551261902   accuracy :  0.6811000108718872 val_acc:  0.6815999746322632 val_binary_acc 0.8745999932289124\n",
      "epoch :  159   cost :  1.056853425502777   accuracy :  0.6822111010551453 val_acc:  0.6823999881744385 val_binary_acc 0.8756999969482422\n",
      "epoch :  160   cost :  1.0581509351730347   accuracy :  0.676288902759552 val_acc:  0.675000011920929 val_binary_acc 0.8694999814033508\n",
      "epoch :  161   cost :  1.0587416529655456   accuracy :  0.6793000102043152 val_acc:  0.6794999837875366 val_binary_acc 0.8734999895095825\n",
      "epoch :  162   cost :  1.0574708938598634   accuracy :  0.6815444231033325 val_acc:  0.682699978351593 val_binary_acc 0.8765000104904175\n",
      "epoch :  163   cost :  1.0547987461090087   accuracy :  0.6833666563034058 val_acc:  0.6833000183105469 val_binary_acc 0.8772000074386597\n",
      "epoch :  164   cost :  1.0544209122657775   accuracy :  0.6820777654647827 val_acc:  0.6818000078201294 val_binary_acc 0.880299985408783\n",
      "epoch :  165   cost :  1.0542508363723755   accuracy :  0.6836110949516296 val_acc:  0.685699999332428 val_binary_acc 0.8776999711990356\n",
      "epoch :  166   cost :  1.053011453151703   accuracy :  0.6818444728851318 val_acc:  0.6800000071525574 val_binary_acc 0.8774999976158142\n",
      "epoch :  167   cost :  1.0530892610549927   accuracy :  0.684344470500946 val_acc:  0.6844000220298767 val_binary_acc 0.8790000081062317\n",
      "epoch :  168   cost :  1.0524640083312988   accuracy :  0.683722198009491 val_acc:  0.6832000017166138 val_binary_acc 0.8777999877929688\n",
      "epoch :  169   cost :  1.0525955438613892   accuracy :  0.6854777932167053 val_acc:  0.6862000226974487 val_binary_acc 0.8766000270843506\n",
      "epoch :  170   cost :  1.0528507232666016   accuracy :  0.6838777661323547 val_acc:  0.6840000152587891 val_binary_acc 0.876800000667572\n",
      "epoch :  171   cost :  1.052713751792908   accuracy :  0.6847888827323914 val_acc:  0.6829000115394592 val_binary_acc 0.8766000270843506\n",
      "epoch :  172   cost :  1.0523747086524964   accuracy :  0.6831889152526855 val_acc:  0.682699978351593 val_binary_acc 0.8772000074386597\n",
      "epoch :  173   cost :  1.0530181288719176   accuracy :  0.6831222176551819 val_acc:  0.6815000176429749 val_binary_acc 0.8766999840736389\n",
      "epoch :  174   cost :  1.0531710028648378   accuracy :  0.6847777962684631 val_acc:  0.6855999827384949 val_binary_acc 0.8791999816894531\n",
      "epoch :  175   cost :  1.0526233673095704   accuracy :  0.6861888766288757 val_acc:  0.6866999864578247 val_binary_acc 0.8784000277519226\n",
      "epoch :  176   cost :  1.051360309123993   accuracy :  0.6864444613456726 val_acc:  0.6870999932289124 val_binary_acc 0.8783000111579895\n",
      "epoch :  177   cost :  1.051156795024872   accuracy :  0.6862333416938782 val_acc:  0.6848999857902527 val_binary_acc 0.878600001335144\n",
      "epoch :  178   cost :  1.0509883999824525   accuracy :  0.6854888796806335 val_acc:  0.6850000023841858 val_binary_acc 0.8769000172615051\n",
      "epoch :  179   cost :  1.0516186118125916   accuracy :  0.6814000010490417 val_acc:  0.6764000058174133 val_binary_acc 0.8784999847412109\n",
      "epoch :  180   cost :  1.0522159934043884   accuracy :  0.6857110857963562 val_acc:  0.6854000091552734 val_binary_acc 0.8794000148773193\n",
      "epoch :  181   cost :  1.0523120880126953   accuracy :  0.6845999956130981 val_acc:  0.6834999918937683 val_binary_acc 0.8770999908447266\n",
      "epoch :  182   cost :  1.0509070873260498   accuracy :  0.6829333305358887 val_acc:  0.6802999973297119 val_binary_acc 0.879800021648407\n",
      "epoch :  183   cost :  1.051002275943756   accuracy :  0.6847888827323914 val_acc:  0.682699978351593 val_binary_acc 0.8773000240325928\n",
      "epoch :  184   cost :  1.0520730853080749   accuracy :  0.6826111078262329 val_acc:  0.6819999814033508 val_binary_acc 0.8747000098228455\n",
      "epoch :  185   cost :  1.0519849181175231   accuracy :  0.6858333349227905 val_acc:  0.6851000189781189 val_binary_acc 0.8794000148773193\n",
      "epoch :  186   cost :  1.0510415077209474   accuracy :  0.6865110993385315 val_acc:  0.6873000264167786 val_binary_acc 0.8810999989509583\n",
      "epoch :  187   cost :  1.0515538692474364   accuracy :  0.6861888766288757 val_acc:  0.6840000152587891 val_binary_acc 0.8759999871253967\n",
      "epoch :  188   cost :  1.0501803398132326   accuracy :  0.6875777840614319 val_acc:  0.6858999729156494 val_binary_acc 0.8784000277519226\n",
      "epoch :  189   cost :  1.050362741947174   accuracy :  0.6875222325325012 val_acc:  0.6859999895095825 val_binary_acc 0.8788999915122986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  190   cost :  1.0505666971206664   accuracy :  0.6876888871192932 val_acc:  0.6865000128746033 val_binary_acc 0.8762999773025513\n",
      "epoch :  191   cost :  1.0524449467658996   accuracy :  0.686477780342102 val_acc:  0.6840000152587891 val_binary_acc 0.878000020980835\n",
      "epoch :  192   cost :  1.0509405255317688   accuracy :  0.686033308506012 val_acc:  0.6840999722480774 val_binary_acc 0.8766000270843506\n",
      "epoch :  193   cost :  1.0499978065490723   accuracy :  0.6875110864639282 val_acc:  0.6870999932289124 val_binary_acc 0.8769999742507935\n",
      "epoch :  194   cost :  1.0495447397232056   accuracy :  0.6883666515350342 val_acc:  0.6866000294685364 val_binary_acc 0.8791999816894531\n",
      "epoch :  195   cost :  1.0489152908325194   accuracy :  0.6886110901832581 val_acc:  0.6876000165939331 val_binary_acc 0.878600001335144\n",
      "epoch :  196   cost :  1.0494447588920595   accuracy :  0.6887555718421936 val_acc:  0.6862000226974487 val_binary_acc 0.8773999810218811\n",
      "epoch :  197   cost :  1.0491017937660216   accuracy :  0.6892222166061401 val_acc:  0.6862000226974487 val_binary_acc 0.8776999711990356\n",
      "epoch :  198   cost :  1.0484906792640687   accuracy :  0.6887000203132629 val_acc:  0.6873000264167786 val_binary_acc 0.8772000074386597\n",
      "epoch :  199   cost :  1.0484554290771484   accuracy :  0.6898999810218811 val_acc:  0.6875 val_binary_acc 0.8797000050544739\n",
      "epoch :  200   cost :  1.0488698720932008   accuracy :  0.6862221956253052 val_acc:  0.6822999715805054 val_binary_acc 0.8794999718666077\n",
      "epoch :  201   cost :  1.0494190335273743   accuracy :  0.6886555552482605 val_acc:  0.6851000189781189 val_binary_acc 0.8791000247001648\n",
      "epoch :  202   cost :  1.0486519932746887   accuracy :  0.6883000135421753 val_acc:  0.6858000159263611 val_binary_acc 0.8779000043869019\n",
      "epoch :  203   cost :  1.0486061930656432   accuracy :  0.6888777613639832 val_acc:  0.6862000226974487 val_binary_acc 0.8763999938964844\n",
      "epoch :  204   cost :  1.048988926410675   accuracy :  0.6871888637542725 val_acc:  0.6847000122070312 val_binary_acc 0.880299985408783\n",
      "epoch :  205   cost :  1.049449050426483   accuracy :  0.6876888871192932 val_acc:  0.6848999857902527 val_binary_acc 0.8763999938964844\n",
      "epoch :  206   cost :  1.0497307300567627   accuracy :  0.6885333061218262 val_acc:  0.6870999932289124 val_binary_acc 0.8792999982833862\n",
      "epoch :  207   cost :  1.0496894598007203   accuracy :  0.6890888810157776 val_acc:  0.6880999803543091 val_binary_acc 0.880299985408783\n",
      "epoch :  208   cost :  1.048583483695984   accuracy :  0.688966691493988 val_acc:  0.6854000091552734 val_binary_acc 0.8770999908447266\n",
      "epoch :  209   cost :  1.0479515314102172   accuracy :  0.6897333264350891 val_acc:  0.6875 val_binary_acc 0.880299985408783\n",
      "epoch :  210   cost :  1.0481821537017821   accuracy :  0.6896777749061584 val_acc:  0.6869999766349792 val_binary_acc 0.8777999877929688\n",
      "epoch :  211   cost :  1.0479248881340026   accuracy :  0.6892777681350708 val_acc:  0.6854000091552734 val_binary_acc 0.8769000172615051\n",
      "epoch :  212   cost :  1.0477051854133606   accuracy :  0.689988911151886 val_acc:  0.6854000091552734 val_binary_acc 0.8794000148773193\n",
      "epoch :  213   cost :  1.047789168357849   accuracy :  0.6867666840553284 val_acc:  0.6798999905586243 val_binary_acc 0.8772000074386597\n",
      "epoch :  214   cost :  1.0468923926353455   accuracy :  0.6913222074508667 val_acc:  0.6883999705314636 val_binary_acc 0.8815000057220459\n",
      "epoch :  215   cost :  1.0461567878723144   accuracy :  0.690833330154419 val_acc:  0.6848999857902527 val_binary_acc 0.8784999847412109\n",
      "epoch :  216   cost :  1.0464477300643922   accuracy :  0.6894888877868652 val_acc:  0.682699978351593 val_binary_acc 0.8791999816894531\n",
      "epoch :  217   cost :  1.0466088771820068   accuracy :  0.6894555687904358 val_acc:  0.6861000061035156 val_binary_acc 0.8798999786376953\n",
      "epoch :  218   cost :  1.0465618848800657   accuracy :  0.6908555626869202 val_acc:  0.6855000257492065 val_binary_acc 0.8835999965667725\n",
      "epoch :  219   cost :  1.0486893892288207   accuracy :  0.6869000196456909 val_acc:  0.6825000047683716 val_binary_acc 0.8774999976158142\n",
      "epoch :  220   cost :  1.0483614563941956   accuracy :  0.6886444687843323 val_acc:  0.6861000061035156 val_binary_acc 0.8758999705314636\n",
      "epoch :  221   cost :  1.0462944984436036   accuracy :  0.689633309841156 val_acc:  0.6861000061035156 val_binary_acc 0.8820000290870667\n",
      "epoch :  222   cost :  1.0456979751586915   accuracy :  0.6929110884666443 val_acc:  0.6876000165939331 val_binary_acc 0.8817999958992004\n",
      "epoch :  223   cost :  1.0446688532829285   accuracy :  0.6926666498184204 val_acc:  0.6876999735832214 val_binary_acc 0.8784000277519226\n",
      "epoch :  224   cost :  1.0444061517715455   accuracy :  0.6936444640159607 val_acc:  0.6881999969482422 val_binary_acc 0.878600001335144\n",
      "epoch :  225   cost :  1.0439456820487976   accuracy :  0.6933333277702332 val_acc:  0.6876000165939331 val_binary_acc 0.8787000179290771\n",
      "epoch :  226   cost :  1.0440546989440918   accuracy :  0.6925888657569885 val_acc:  0.6875 val_binary_acc 0.8791999816894531\n",
      "epoch :  227   cost :  1.0445127844810487   accuracy :  0.6930888891220093 val_acc:  0.6887000203132629 val_binary_acc 0.8802000284194946\n",
      "epoch :  228   cost :  1.0439756989479065   accuracy :  0.6940222382545471 val_acc:  0.6883000135421753 val_binary_acc 0.8804000020027161\n",
      "epoch :  229   cost :  1.0437567949295044   accuracy :  0.6936444640159607 val_acc:  0.6859999895095825 val_binary_acc 0.8804000020027161\n",
      "epoch :  230   cost :  1.04426509141922   accuracy :  0.6921777725219727 val_acc:  0.6884999871253967 val_binary_acc 0.8787000179290771\n",
      "epoch :  231   cost :  1.044518029689789   accuracy :  0.6933000087738037 val_acc:  0.6862999796867371 val_binary_acc 0.8815000057220459\n",
      "epoch :  232   cost :  1.0444424748420715   accuracy :  0.6922555565834045 val_acc:  0.6862000226974487 val_binary_acc 0.8798999786376953\n",
      "epoch :  233   cost :  1.044016993045807   accuracy :  0.6941333413124084 val_acc:  0.6854000091552734 val_binary_acc 0.880299985408783\n",
      "epoch :  234   cost :  1.0433848738670348   accuracy :  0.6935111284255981 val_acc:  0.6869999766349792 val_binary_acc 0.8806999921798706\n",
      "epoch :  235   cost :  1.0432118892669677   accuracy :  0.6940222382545471 val_acc:  0.6901999711990356 val_binary_acc 0.8795999884605408\n",
      "epoch :  236   cost :  1.042984652519226   accuracy :  0.6937000155448914 val_acc:  0.6869999766349792 val_binary_acc 0.8773999810218811\n",
      "epoch :  237   cost :  1.0426992416381835   accuracy :  0.6936777830123901 val_acc:  0.6884999871253967 val_binary_acc 0.8809999823570251\n",
      "epoch :  238   cost :  1.0425635933876038   accuracy :  0.6928555369377136 val_acc:  0.6834999918937683 val_binary_acc 0.8744000196456909\n",
      "epoch :  239   cost :  1.0423830509185792   accuracy :  0.6956222057342529 val_acc:  0.6891000270843506 val_binary_acc 0.8799999952316284\n",
      "epoch :  240   cost :  1.0412140250205995   accuracy :  0.6964777708053589 val_acc:  0.6912000179290771 val_binary_acc 0.879800021648407\n",
      "epoch :  241   cost :  1.041189730167389   accuracy :  0.6958777904510498 val_acc:  0.6899999976158142 val_binary_acc 0.8776999711990356\n",
      "epoch :  242   cost :  1.0411520242691041   accuracy :  0.6934999823570251 val_acc:  0.6854000091552734 val_binary_acc 0.8801000118255615\n",
      "epoch :  243   cost :  1.0416067600250245   accuracy :  0.6973555684089661 val_acc:  0.6894999742507935 val_binary_acc 0.8790000081062317\n",
      "epoch :  244   cost :  1.0415048122406005   accuracy :  0.6955999732017517 val_acc:  0.6902999877929688 val_binary_acc 0.8794999718666077\n",
      "epoch :  245   cost :  1.0427547812461855   accuracy :  0.6940555572509766 val_acc:  0.6881999969482422 val_binary_acc 0.8744000196456909\n",
      "epoch :  246   cost :  1.041424298286438   accuracy :  0.6961555480957031 val_acc:  0.6906999945640564 val_binary_acc 0.8776000142097473\n",
      "epoch :  247   cost :  1.0402640104293823   accuracy :  0.6968111395835876 val_acc:  0.6912000179290771 val_binary_acc 0.8780999779701233\n",
      "epoch :  248   cost :  1.0399455308914183   accuracy :  0.6978111267089844 val_acc:  0.6916999816894531 val_binary_acc 0.8787999749183655\n",
      "epoch :  249   cost :  1.0398721098899841   accuracy :  0.697088897228241 val_acc:  0.6886000037193298 val_binary_acc 0.879800021648407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  250   cost :  1.0408227682113647   accuracy :  0.6956111192703247 val_acc:  0.6897000074386597 val_binary_acc 0.8830999732017517\n",
      "epoch :  251   cost :  1.041031527519226   accuracy :  0.6969444155693054 val_acc:  0.6905999779701233 val_binary_acc 0.8788999915122986\n",
      "epoch :  252   cost :  1.0402034521102905   accuracy :  0.6988000273704529 val_acc:  0.6917999982833862 val_binary_acc 0.879800021648407\n",
      "epoch :  253   cost :  1.039335584640503   accuracy :  0.6987555623054504 val_acc:  0.6929000020027161 val_binary_acc 0.8819000124931335\n",
      "epoch :  254   cost :  1.040118610858917   accuracy :  0.6975666880607605 val_acc:  0.6904000043869019 val_binary_acc 0.879800021648407\n",
      "epoch :  255   cost :  1.0396098613739015   accuracy :  0.697422206401825 val_acc:  0.6904000043869019 val_binary_acc 0.8806999921798706\n",
      "epoch :  256   cost :  1.0401479840278625   accuracy :  0.6980555653572083 val_acc:  0.6916000247001648 val_binary_acc 0.8792999982833862\n",
      "epoch :  257   cost :  1.0400457501411438   accuracy :  0.6988111138343811 val_acc:  0.6920999884605408 val_binary_acc 0.8809000253677368\n",
      "epoch :  258   cost :  1.0393234729766845   accuracy :  0.6953555345535278 val_acc:  0.6887000203132629 val_binary_acc 0.8762000203132629\n",
      "epoch :  259   cost :  1.0411924600601197   accuracy :  0.6954444646835327 val_acc:  0.6861000061035156 val_binary_acc 0.8805999755859375\n",
      "epoch :  260   cost :  1.040980362892151   accuracy :  0.6978889107704163 val_acc:  0.6897000074386597 val_binary_acc 0.8776000142097473\n",
      "epoch :  261   cost :  1.0394487977027893   accuracy :  0.6975555419921875 val_acc:  0.6915000081062317 val_binary_acc 0.8766999840736389\n",
      "epoch :  262   cost :  1.0391324281692504   accuracy :  0.6989666819572449 val_acc:  0.6920999884605408 val_binary_acc 0.8769999742507935\n",
      "epoch :  263   cost :  1.0381437659263613   accuracy :  0.6984666585922241 val_acc:  0.6924999952316284 val_binary_acc 0.8777999877929688\n",
      "epoch :  264   cost :  1.0382641911506654   accuracy :  0.6981666684150696 val_acc:  0.6924999952316284 val_binary_acc 0.8792999982833862\n",
      "epoch :  265   cost :  1.0381849646568297   accuracy :  0.6984111070632935 val_acc:  0.6919000148773193 val_binary_acc 0.8776999711990356\n",
      "epoch :  266   cost :  1.038533055782318   accuracy :  0.6987777948379517 val_acc:  0.6922000050544739 val_binary_acc 0.879800021648407\n",
      "epoch :  267   cost :  1.0385270833969116   accuracy :  0.7004777789115906 val_acc:  0.6934000253677368 val_binary_acc 0.8823000192642212\n",
      "epoch :  268   cost :  1.0378485321998598   accuracy :  0.6991555690765381 val_acc:  0.6913999915122986 val_binary_acc 0.8784000277519226\n",
      "epoch :  269   cost :  1.0382437467575074   accuracy :  0.6993666887283325 val_acc:  0.6919999718666077 val_binary_acc 0.8805999755859375\n",
      "epoch :  270   cost :  1.0373437523841857   accuracy :  0.7013333439826965 val_acc:  0.6929000020027161 val_binary_acc 0.8805999755859375\n",
      "epoch :  271   cost :  1.0368266820907592   accuracy :  0.7003333568572998 val_acc:  0.6933000087738037 val_binary_acc 0.8787000179290771\n",
      "epoch :  272   cost :  1.0372392416000367   accuracy :  0.6988222002983093 val_acc:  0.6866000294685364 val_binary_acc 0.8826000094413757\n",
      "epoch :  273   cost :  1.0372806310653686   accuracy :  0.7002221941947937 val_acc:  0.692300021648407 val_binary_acc 0.878600001335144\n",
      "epoch :  274   cost :  1.0377984404563902   accuracy :  0.698711097240448 val_acc:  0.691100001335144 val_binary_acc 0.8774999976158142\n",
      "epoch :  275   cost :  1.0377813577651978   accuracy :  0.6990666389465332 val_acc:  0.690500020980835 val_binary_acc 0.8788999915122986\n",
      "epoch :  276   cost :  1.0365903973579407   accuracy :  0.7008000016212463 val_acc:  0.6915000081062317 val_binary_acc 0.8799999952316284\n",
      "epoch :  277   cost :  1.0365506887435914   accuracy :  0.6986333131790161 val_acc:  0.6890000104904175 val_binary_acc 0.8777999877929688\n",
      "epoch :  278   cost :  1.0367882013320924   accuracy :  0.6995777487754822 val_acc:  0.6917999982833862 val_binary_acc 0.8812999725341797\n",
      "epoch :  279   cost :  1.0369064688682554   accuracy :  0.7013221979141235 val_acc:  0.6941999793052673 val_binary_acc 0.8794000148773193\n",
      "epoch :  280   cost :  1.0355194807052612   accuracy :  0.7020221948623657 val_acc:  0.6945000290870667 val_binary_acc 0.880299985408783\n",
      "epoch :  281   cost :  1.0361323356628418   accuracy :  0.7010999917984009 val_acc:  0.692300021648407 val_binary_acc 0.8773999810218811\n",
      "epoch :  282   cost :  1.0359450340270997   accuracy :  0.7008666396141052 val_acc:  0.6933000087738037 val_binary_acc 0.8815000057220459\n",
      "epoch :  283   cost :  1.0363354206085205   accuracy :  0.7022333145141602 val_acc:  0.6922000050544739 val_binary_acc 0.8805999755859375\n",
      "epoch :  284   cost :  1.0361332654953006   accuracy :  0.7009555697441101 val_acc:  0.6938999891281128 val_binary_acc 0.8769999742507935\n",
      "epoch :  285   cost :  1.0360936522483823   accuracy :  0.7021444439888 val_acc:  0.6937000155448914 val_binary_acc 0.8813999891281128\n",
      "epoch :  286   cost :  1.0362520098686219   accuracy :  0.7013000249862671 val_acc:  0.6945000290870667 val_binary_acc 0.8823000192642212\n",
      "epoch :  287   cost :  1.0364783167839051   accuracy :  0.7017555832862854 val_acc:  0.6929000020027161 val_binary_acc 0.8809000253677368\n",
      "epoch :  288   cost :  1.0356116771697998   accuracy :  0.7006000280380249 val_acc:  0.6935999989509583 val_binary_acc 0.8797000050544739\n",
      "epoch :  289   cost :  1.0353100538253783   accuracy :  0.701877772808075 val_acc:  0.6947000026702881 val_binary_acc 0.8791000247001648\n",
      "epoch :  290   cost :  1.0356130123138427   accuracy :  0.7018888592720032 val_acc:  0.6930999755859375 val_binary_acc 0.8820000290870667\n",
      "epoch :  291   cost :  1.035140061378479   accuracy :  0.7012222409248352 val_acc:  0.6924999952316284 val_binary_acc 0.8804000020027161\n",
      "epoch :  292   cost :  1.0353100538253783   accuracy :  0.7033666372299194 val_acc:  0.6951000094413757 val_binary_acc 0.8809999823570251\n",
      "epoch :  293   cost :  1.034662628173828   accuracy :  0.7027111053466797 val_acc:  0.6933000087738037 val_binary_acc 0.8794999718666077\n",
      "epoch :  294   cost :  1.0354626297950744   accuracy :  0.7008110880851746 val_acc:  0.6934999823570251 val_binary_acc 0.8804000020027161\n",
      "epoch :  295   cost :  1.0354480504989623   accuracy :  0.7034111022949219 val_acc:  0.6952000260353088 val_binary_acc 0.8791999816894531\n",
      "epoch :  296   cost :  1.0337022066116333   accuracy :  0.7041333317756653 val_acc:  0.6940000057220459 val_binary_acc 0.8823999762535095\n",
      "epoch :  297   cost :  1.0345218420028686   accuracy :  0.7036222219467163 val_acc:  0.6940000057220459 val_binary_acc 0.8787999749183655\n",
      "epoch :  298   cost :  1.0352540612220764   accuracy :  0.7041000127792358 val_acc:  0.6952999830245972 val_binary_acc 0.8794999718666077\n",
      "epoch :  299   cost :  1.034752142429352   accuracy :  0.7034444212913513 val_acc:  0.6933000087738037 val_binary_acc 0.8795999884605408\n",
      "epoch :  300   cost :  1.0339912295341491   accuracy :  0.7041222453117371 val_acc:  0.6952999830245972 val_binary_acc 0.8798999786376953\n",
      "epoch :  301   cost :  1.033699572086334   accuracy :  0.7027000188827515 val_acc:  0.6948999762535095 val_binary_acc 0.8809000253677368\n",
      "epoch :  302   cost :  1.033738374710083   accuracy :  0.7041777968406677 val_acc:  0.6947000026702881 val_binary_acc 0.8816999793052673\n",
      "epoch :  303   cost :  1.033686363697052   accuracy :  0.7034888863563538 val_acc:  0.6934000253677368 val_binary_acc 0.8809999823570251\n",
      "epoch :  304   cost :  1.034036946296692   accuracy :  0.7038333415985107 val_acc:  0.6959999799728394 val_binary_acc 0.8805999755859375\n",
      "epoch :  305   cost :  1.0337440133094786   accuracy :  0.7038000226020813 val_acc:  0.692799985408783 val_binary_acc 0.8802000284194946\n",
      "epoch :  306   cost :  1.0338215231895447   accuracy :  0.7030888795852661 val_acc:  0.6934999823570251 val_binary_acc 0.8791000247001648\n",
      "epoch :  307   cost :  1.034245753288269   accuracy :  0.7039222121238708 val_acc:  0.6947000026702881 val_binary_acc 0.8791999816894531\n",
      "epoch :  308   cost :  1.033909273147583   accuracy :  0.7035555839538574 val_acc:  0.6933000087738037 val_binary_acc 0.8808000087738037\n",
      "epoch :  309   cost :  1.0334550976753234   accuracy :  0.7039889097213745 val_acc:  0.6930999755859375 val_binary_acc 0.8806999921798706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  310   cost :  1.0335132479667664   accuracy :  0.7026777863502502 val_acc:  0.6916999816894531 val_binary_acc 0.8799999952316284\n",
      "epoch :  311   cost :  1.0332170367240905   accuracy :  0.7040333151817322 val_acc:  0.6956999897956848 val_binary_acc 0.8763999938964844\n",
      "epoch :  312   cost :  1.0323803424835205   accuracy :  0.7048888802528381 val_acc:  0.6952000260353088 val_binary_acc 0.8813999891281128\n",
      "epoch :  313   cost :  1.0321272373199464   accuracy :  0.70615553855896 val_acc:  0.6966000199317932 val_binary_acc 0.8780999779701233\n",
      "epoch :  314   cost :  1.0316147685050965   accuracy :  0.7061777710914612 val_acc:  0.6931999921798706 val_binary_acc 0.8823999762535095\n",
      "epoch :  315   cost :  1.031575608253479   accuracy :  0.7047222256660461 val_acc:  0.6949999928474426 val_binary_acc 0.8806999921798706\n",
      "epoch :  316   cost :  1.0319530010223388   accuracy :  0.7061777710914612 val_acc:  0.694599986076355 val_binary_acc 0.8823999762535095\n",
      "epoch :  317   cost :  1.0309269785881043   accuracy :  0.7070333361625671 val_acc:  0.6977999806404114 val_binary_acc 0.8809000253677368\n",
      "epoch :  318   cost :  1.0310913801193238   accuracy :  0.7073000073432922 val_acc:  0.6931999921798706 val_binary_acc 0.878600001335144\n",
      "epoch :  319   cost :  1.0305926918983461   accuracy :  0.70660001039505 val_acc:  0.6952999830245972 val_binary_acc 0.878000020980835\n",
      "epoch :  320   cost :  1.0309014201164246   accuracy :  0.7072222232818604 val_acc:  0.6948999762535095 val_binary_acc 0.8776000142097473\n",
      "epoch :  321   cost :  1.0312233328819276   accuracy :  0.7034333348274231 val_acc:  0.6933000087738037 val_binary_acc 0.8806999921798706\n",
      "epoch :  322   cost :  1.0322880029678345   accuracy :  0.7048777937889099 val_acc:  0.694599986076355 val_binary_acc 0.883400022983551\n",
      "epoch :  323   cost :  1.0319954752922058   accuracy :  0.7073222398757935 val_acc:  0.6969000101089478 val_binary_acc 0.8812000155448914\n",
      "epoch :  324   cost :  1.0310582876205445   accuracy :  0.7076444625854492 val_acc:  0.694100022315979 val_binary_acc 0.8808000087738037\n",
      "epoch :  325   cost :  1.0304905652999878   accuracy :  0.7068444490432739 val_acc:  0.6948999762535095 val_binary_acc 0.8820000290870667\n",
      "epoch :  326   cost :  1.0310909867286682   accuracy :  0.7075111269950867 val_acc:  0.6969000101089478 val_binary_acc 0.8812999725341797\n",
      "epoch :  327   cost :  1.0311790466308595   accuracy :  0.7062222361564636 val_acc:  0.6952000260353088 val_binary_acc 0.8769999742507935\n",
      "epoch :  328   cost :  1.0302494883537292   accuracy :  0.7078111171722412 val_acc:  0.696399986743927 val_binary_acc 0.8806999921798706\n",
      "epoch :  329   cost :  1.0302975296974182   accuracy :  0.7081778049468994 val_acc:  0.697700023651123 val_binary_acc 0.8805999755859375\n",
      "epoch :  330   cost :  1.0296195030212403   accuracy :  0.708311140537262 val_acc:  0.6951000094413757 val_binary_acc 0.8809999823570251\n",
      "epoch :  331   cost :  1.0297217130661012   accuracy :  0.7068444490432739 val_acc:  0.6960999965667725 val_binary_acc 0.8826000094413757\n",
      "epoch :  332   cost :  1.0301863670349123   accuracy :  0.7082444429397583 val_acc:  0.6965000033378601 val_binary_acc 0.8791999816894531\n",
      "epoch :  333   cost :  1.0293933868408203   accuracy :  0.7089889049530029 val_acc:  0.6967999935150146 val_binary_acc 0.8816999793052673\n",
      "epoch :  334   cost :  1.029227387905121   accuracy :  0.7086222171783447 val_acc:  0.6951000094413757 val_binary_acc 0.8787999749183655\n",
      "epoch :  335   cost :  1.0291732311248778   accuracy :  0.7077111005783081 val_acc:  0.6952999830245972 val_binary_acc 0.8815000057220459\n",
      "epoch :  336   cost :  1.0290969729423523   accuracy :  0.708899974822998 val_acc:  0.6970000267028809 val_binary_acc 0.879800021648407\n",
      "epoch :  337   cost :  1.02891343832016   accuracy :  0.7084110975265503 val_acc:  0.6951000094413757 val_binary_acc 0.8804000020027161\n",
      "epoch :  338   cost :  1.028714382648468   accuracy :  0.7091444730758667 val_acc:  0.6972000002861023 val_binary_acc 0.8806999921798706\n",
      "epoch :  339   cost :  1.0292299151420594   accuracy :  0.7085888981819153 val_acc:  0.695900022983551 val_binary_acc 0.8792999982833862\n",
      "epoch :  340   cost :  1.0290908217430115   accuracy :  0.7086889147758484 val_acc:  0.6970000267028809 val_binary_acc 0.8826000094413757\n",
      "epoch :  341   cost :  1.0294009685516357   accuracy :  0.7073888778686523 val_acc:  0.6952999830245972 val_binary_acc 0.8784999847412109\n",
      "epoch :  342   cost :  1.0292632937431334   accuracy :  0.707955539226532 val_acc:  0.6959999799728394 val_binary_acc 0.882099986076355\n",
      "epoch :  343   cost :  1.0290011882781982   accuracy :  0.7091777920722961 val_acc:  0.6956999897956848 val_binary_acc 0.8827999830245972\n",
      "epoch :  344   cost :  1.0284161329269408   accuracy :  0.7087666392326355 val_acc:  0.6945000290870667 val_binary_acc 0.8805999755859375\n",
      "epoch :  345   cost :  1.028744626045227   accuracy :  0.7082777619361877 val_acc:  0.694599986076355 val_binary_acc 0.880299985408783\n",
      "epoch :  346   cost :  1.0285061717033386   accuracy :  0.7098666429519653 val_acc:  0.6987000107765198 val_binary_acc 0.881600022315979\n",
      "epoch :  347   cost :  1.0287350296974183   accuracy :  0.7095222473144531 val_acc:  0.695900022983551 val_binary_acc 0.8795999884605408\n",
      "epoch :  348   cost :  1.0288505911827088   accuracy :  0.7082444429397583 val_acc:  0.6958000063896179 val_binary_acc 0.8795999884605408\n",
      "epoch :  349   cost :  1.0287585020065309   accuracy :  0.7096666693687439 val_acc:  0.6962000131607056 val_binary_acc 0.8798999786376953\n",
      "epoch :  350   cost :  1.028410840034485   accuracy :  0.7079111337661743 val_acc:  0.6948000192642212 val_binary_acc 0.8812000155448914\n",
      "epoch :  351   cost :  1.0283348679542543   accuracy :  0.7105110883712769 val_acc:  0.6970999836921692 val_binary_acc 0.8816999793052673\n",
      "epoch :  352   cost :  1.0280212283134458   accuracy :  0.7090222239494324 val_acc:  0.6966999769210815 val_binary_acc 0.8787000179290771\n",
      "epoch :  353   cost :  1.0284061431884766   accuracy :  0.7081888914108276 val_acc:  0.6952000260353088 val_binary_acc 0.8809999823570251\n",
      "epoch :  354   cost :  1.0291460514068604   accuracy :  0.7087222337722778 val_acc:  0.6963000297546387 val_binary_acc 0.8828999996185303\n",
      "epoch :  355   cost :  1.0290682435035707   accuracy :  0.7081999778747559 val_acc:  0.6955999732017517 val_binary_acc 0.8823000192642212\n",
      "epoch :  356   cost :  1.0281736373901367   accuracy :  0.7089333534240723 val_acc:  0.6966000199317932 val_binary_acc 0.8798999786376953\n",
      "epoch :  357   cost :  1.0272620201110838   accuracy :  0.7107555270195007 val_acc:  0.6966999769210815 val_binary_acc 0.8791999816894531\n",
      "epoch :  358   cost :  1.0273716568946838   accuracy :  0.710788905620575 val_acc:  0.6969000101089478 val_binary_acc 0.8812999725341797\n",
      "epoch :  359   cost :  1.0272248268127442   accuracy :  0.7093333601951599 val_acc:  0.6955999732017517 val_binary_acc 0.8791000247001648\n",
      "epoch :  360   cost :  1.027659571170807   accuracy :  0.710777759552002 val_acc:  0.695900022983551 val_binary_acc 0.8805000185966492\n",
      "epoch :  361   cost :  1.0274411678314208   accuracy :  0.7116666436195374 val_acc:  0.6991999745368958 val_binary_acc 0.8823000192642212\n",
      "epoch :  362   cost :  1.0265370368957518   accuracy :  0.7109000086784363 val_acc:  0.6966000199317932 val_binary_acc 0.8801000118255615\n",
      "epoch :  363   cost :  1.0261288285255432   accuracy :  0.7121999859809875 val_acc:  0.6973999738693237 val_binary_acc 0.8805000185966492\n",
      "epoch :  364   cost :  1.0261215806007384   accuracy :  0.7107666730880737 val_acc:  0.6970999836921692 val_binary_acc 0.8802000284194946\n",
      "epoch :  365   cost :  1.026661741733551   accuracy :  0.7116888761520386 val_acc:  0.6973999738693237 val_binary_acc 0.883400022983551\n",
      "epoch :  366   cost :  1.0264060139656068   accuracy :  0.7109110951423645 val_acc:  0.6958000063896179 val_binary_acc 0.882099986076355\n",
      "epoch :  367   cost :  1.0274369955062865   accuracy :  0.7101777791976929 val_acc:  0.6966000199317932 val_binary_acc 0.8827999830245972\n",
      "epoch :  368   cost :  1.0266782522201539   accuracy :  0.7117999792098999 val_acc:  0.6980000138282776 val_binary_acc 0.8813999891281128\n",
      "epoch :  369   cost :  1.0262829422950746   accuracy :  0.7114333510398865 val_acc:  0.6984000205993652 val_binary_acc 0.8812000155448914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  370   cost :  1.0263259887695315   accuracy :  0.7121888995170593 val_acc:  0.6978999972343445 val_binary_acc 0.8804000020027161\n",
      "epoch :  371   cost :  1.0265491962432862   accuracy :  0.7079889178276062 val_acc:  0.694599986076355 val_binary_acc 0.8816999793052673\n",
      "epoch :  372   cost :  1.029103684425354   accuracy :  0.7072666883468628 val_acc:  0.6953999996185303 val_binary_acc 0.8823000192642212\n",
      "epoch :  373   cost :  1.0302400469779969   accuracy :  0.7070000171661377 val_acc:  0.6930000185966492 val_binary_acc 0.8827999830245972\n",
      "epoch :  374   cost :  1.0291722178459168   accuracy :  0.7099888920783997 val_acc:  0.6960999965667725 val_binary_acc 0.8790000081062317\n",
      "epoch :  375   cost :  1.0276942491531373   accuracy :  0.7099666595458984 val_acc:  0.6955999732017517 val_binary_acc 0.882099986076355\n",
      "epoch :  376   cost :  1.026744890213013   accuracy :  0.711222231388092 val_acc:  0.6970999836921692 val_binary_acc 0.880299985408783\n",
      "epoch :  377   cost :  1.0263341426849366   accuracy :  0.7124666571617126 val_acc:  0.6965000033378601 val_binary_acc 0.8794999718666077\n",
      "epoch :  378   cost :  1.0263992190361022   accuracy :  0.7111444473266602 val_acc:  0.6970999836921692 val_binary_acc 0.8817999958992004\n",
      "epoch :  379   cost :  1.0260438919067383   accuracy :  0.7102222442626953 val_acc:  0.694599986076355 val_binary_acc 0.8808000087738037\n",
      "epoch :  380   cost :  1.0259386897087097   accuracy :  0.7118889093399048 val_acc:  0.6970000267028809 val_binary_acc 0.8813999891281128\n",
      "epoch :  381   cost :  1.0252482891082764   accuracy :  0.7110888957977295 val_acc:  0.6949999928474426 val_binary_acc 0.8805999755859375\n",
      "epoch :  382   cost :  1.02580384016037   accuracy :  0.7123222351074219 val_acc:  0.6976000070571899 val_binary_acc 0.881600022315979\n",
      "epoch :  383   cost :  1.025932514667511   accuracy :  0.7128333449363708 val_acc:  0.6973999738693237 val_binary_acc 0.8812999725341797\n",
      "epoch :  384   cost :  1.0255186319351197   accuracy :  0.7120333313941956 val_acc:  0.6966000199317932 val_binary_acc 0.8787999749183655\n",
      "epoch :  385   cost :  1.0248957514762878   accuracy :  0.7129444479942322 val_acc:  0.6973000168800354 val_binary_acc 0.8827999830245972\n",
      "epoch :  386   cost :  1.024760138988495   accuracy :  0.7127110958099365 val_acc:  0.6977999806404114 val_binary_acc 0.8798999786376953\n",
      "epoch :  387   cost :  1.025025486946106   accuracy :  0.7125666737556458 val_acc:  0.6953999996185303 val_binary_acc 0.878600001335144\n",
      "epoch :  388   cost :  1.0254863142967223   accuracy :  0.7120000123977661 val_acc:  0.6952999830245972 val_binary_acc 0.8773000240325928\n",
      "epoch :  389   cost :  1.0257279753684998   accuracy :  0.7115333080291748 val_acc:  0.6958000063896179 val_binary_acc 0.882099986076355\n",
      "epoch :  390   cost :  1.0262667179107665   accuracy :  0.713088870048523 val_acc:  0.6970999836921692 val_binary_acc 0.8831999897956848\n",
      "epoch :  391   cost :  1.0249832630157472   accuracy :  0.713088870048523 val_acc:  0.6977999806404114 val_binary_acc 0.882099986076355\n",
      "epoch :  392   cost :  1.0248633742332458   accuracy :  0.7123000025749207 val_acc:  0.6977999806404114 val_binary_acc 0.8823999762535095\n",
      "epoch :  393   cost :  1.0256456255912783   accuracy :  0.7125666737556458 val_acc:  0.6966000199317932 val_binary_acc 0.879800021648407\n",
      "epoch :  394   cost :  1.0253604531288147   accuracy :  0.7117111086845398 val_acc:  0.6963000297546387 val_binary_acc 0.8799999952316284\n",
      "epoch :  395   cost :  1.0249026656150817   accuracy :  0.713355541229248 val_acc:  0.6988999843597412 val_binary_acc 0.8813999891281128\n",
      "epoch :  396   cost :  1.0244187235832214   accuracy :  0.7136555314064026 val_acc:  0.6969000101089478 val_binary_acc 0.8812000155448914\n",
      "epoch :  397   cost :  1.023771870136261   accuracy :  0.7143555283546448 val_acc:  0.6987000107765198 val_binary_acc 0.8827000260353088\n",
      "epoch :  398   cost :  1.0234983444213865   accuracy :  0.7139666676521301 val_acc:  0.6959999799728394 val_binary_acc 0.8805000185966492\n",
      "epoch :  399   cost :  1.0235271453857422   accuracy :  0.7135666608810425 val_acc:  0.6972000002861023 val_binary_acc 0.8822000026702881\n",
      "epoch :  400   cost :  1.0236672043800352   accuracy :  0.7143666744232178 val_acc:  0.6972000002861023 val_binary_acc 0.8812999725341797\n",
      "epoch :  401   cost :  1.0230583429336546   accuracy :  0.7131555676460266 val_acc:  0.6956999897956848 val_binary_acc 0.8804000020027161\n",
      "epoch :  402   cost :  1.0237051844596863   accuracy :  0.714722216129303 val_acc:  0.6977999806404114 val_binary_acc 0.8830000162124634\n",
      "epoch :  403   cost :  1.0233419418334961   accuracy :  0.7139889001846313 val_acc:  0.6972000002861023 val_binary_acc 0.880299985408783\n",
      "epoch :  404   cost :  1.0241639852523803   accuracy :  0.7136777639389038 val_acc:  0.697700023651123 val_binary_acc 0.8812000155448914\n",
      "epoch :  405   cost :  1.0239063858985902   accuracy :  0.7145777940750122 val_acc:  0.6955999732017517 val_binary_acc 0.8812000155448914\n",
      "epoch :  406   cost :  1.0236846923828125   accuracy :  0.7136222124099731 val_acc:  0.6963000297546387 val_binary_acc 0.8790000081062317\n",
      "epoch :  407   cost :  1.0240932822227478   accuracy :  0.714388906955719 val_acc:  0.6977999806404114 val_binary_acc 0.8804000020027161\n",
      "epoch :  408   cost :  1.0242687940597535   accuracy :  0.7130555510520935 val_acc:  0.6942999958992004 val_binary_acc 0.8809000253677368\n",
      "epoch :  409   cost :  1.02443687915802   accuracy :  0.7139333486557007 val_acc:  0.6970000267028809 val_binary_acc 0.8802000284194946\n",
      "epoch :  410   cost :  1.023407232761383   accuracy :  0.7150555849075317 val_acc:  0.6974999904632568 val_binary_acc 0.8809999823570251\n",
      "epoch :  411   cost :  1.02259863615036   accuracy :  0.7145333290100098 val_acc:  0.696399986743927 val_binary_acc 0.881600022315979\n",
      "epoch :  412   cost :  1.0228472232818602   accuracy :  0.7146333456039429 val_acc:  0.6973999738693237 val_binary_acc 0.8812000155448914\n",
      "epoch :  413   cost :  1.0228318333625794   accuracy :  0.7149999737739563 val_acc:  0.696399986743927 val_binary_acc 0.8817999958992004\n",
      "epoch :  414   cost :  1.0233197212219238   accuracy :  0.7141000032424927 val_acc:  0.6949999928474426 val_binary_acc 0.882099986076355\n",
      "epoch :  415   cost :  1.023369264602661   accuracy :  0.7143444418907166 val_acc:  0.695900022983551 val_binary_acc 0.8812000155448914\n",
      "epoch :  416   cost :  1.0229370594024658   accuracy :  0.7144333124160767 val_acc:  0.6967999935150146 val_binary_acc 0.8815000057220459\n",
      "epoch :  417   cost :  1.0227028608322144   accuracy :  0.7151555418968201 val_acc:  0.6980000138282776 val_binary_acc 0.8813999891281128\n",
      "epoch :  418   cost :  1.0229086399078369   accuracy :  0.7152555584907532 val_acc:  0.6965000033378601 val_binary_acc 0.8816999793052673\n",
      "epoch :  419   cost :  1.0229533195495606   accuracy :  0.7146999835968018 val_acc:  0.6955999732017517 val_binary_acc 0.8823000192642212\n",
      "epoch :  420   cost :  1.0230460286140441   accuracy :  0.714377760887146 val_acc:  0.6973000168800354 val_binary_acc 0.8819000124931335\n",
      "epoch :  421   cost :  1.0230608463287354   accuracy :  0.7153000235557556 val_acc:  0.6983000040054321 val_binary_acc 0.8819000124931335\n",
      "epoch :  422   cost :  1.0235800743103027   accuracy :  0.7112888693809509 val_acc:  0.6890000104904175 val_binary_acc 0.8777999877929688\n",
      "epoch :  423   cost :  1.024840307235718   accuracy :  0.7148110866546631 val_acc:  0.697700023651123 val_binary_acc 0.8824999928474426\n",
      "epoch :  424   cost :  1.02368506193161   accuracy :  0.7139000296592712 val_acc:  0.6970000267028809 val_binary_acc 0.8833000063896179\n",
      "epoch :  425   cost :  1.0228493571281432   accuracy :  0.714900016784668 val_acc:  0.6984000205993652 val_binary_acc 0.8805999755859375\n",
      "epoch :  426   cost :  1.022145116329193   accuracy :  0.7157444357872009 val_acc:  0.6978999972343445 val_binary_acc 0.8802000284194946\n",
      "epoch :  427   cost :  1.0216646194458008   accuracy :  0.7156000137329102 val_acc:  0.6987000107765198 val_binary_acc 0.8815000057220459\n",
      "epoch :  428   cost :  1.0219169974327087   accuracy :  0.716188907623291 val_acc:  0.696399986743927 val_binary_acc 0.8820000290870667\n",
      "epoch :  429   cost :  1.0216145873069764   accuracy :  0.7156333327293396 val_acc:  0.698199987411499 val_binary_acc 0.883400022983551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  430   cost :  1.0213598251342775   accuracy :  0.7166222333908081 val_acc:  0.6983000040054321 val_binary_acc 0.8817999958992004\n",
      "epoch :  431   cost :  1.0220470666885375   accuracy :  0.715399980545044 val_acc:  0.695900022983551 val_binary_acc 0.8787999749183655\n",
      "epoch :  432   cost :  1.0214779257774353   accuracy :  0.7162777781486511 val_acc:  0.6966999769210815 val_binary_acc 0.8808000087738037\n",
      "epoch :  433   cost :  1.021674704551697   accuracy :  0.7163222432136536 val_acc:  0.697700023651123 val_binary_acc 0.8816999793052673\n",
      "epoch :  434   cost :  1.0219227790832521   accuracy :  0.7157999873161316 val_acc:  0.6980000138282776 val_binary_acc 0.8822000026702881\n",
      "epoch :  435   cost :  1.0214380860328673   accuracy :  0.7165111303329468 val_acc:  0.6976000070571899 val_binary_acc 0.8809000253677368\n",
      "epoch :  436   cost :  1.0217354059219361   accuracy :  0.7146888971328735 val_acc:  0.6967999935150146 val_binary_acc 0.8794000148773193\n",
      "epoch :  437   cost :  1.0223220467567444   accuracy :  0.7151666879653931 val_acc:  0.6965000033378601 val_binary_acc 0.8806999921798706\n",
      "epoch :  438   cost :  1.0218390583992003   accuracy :  0.7162777781486511 val_acc:  0.6967999935150146 val_binary_acc 0.8797000050544739\n",
      "epoch :  439   cost :  1.0212219119071961   accuracy :  0.716855525970459 val_acc:  0.6983000040054321 val_binary_acc 0.8823000192642212\n",
      "epoch :  440   cost :  1.0214556336402894   accuracy :  0.7163666486740112 val_acc:  0.6966000199317932 val_binary_acc 0.8820000290870667\n",
      "epoch :  441   cost :  1.0213987469673158   accuracy :  0.7166444659233093 val_acc:  0.6978999972343445 val_binary_acc 0.8813999891281128\n",
      "epoch :  442   cost :  1.0211852669715882   accuracy :  0.7158555388450623 val_acc:  0.6983000040054321 val_binary_acc 0.8810999989509583\n",
      "epoch :  443   cost :  1.020947563648224   accuracy :  0.717544436454773 val_acc:  0.698199987411499 val_binary_acc 0.8833000063896179\n",
      "epoch :  444   cost :  1.0206131339073181   accuracy :  0.716522216796875 val_acc:  0.6970000267028809 val_binary_acc 0.8798999786376953\n",
      "epoch :  445   cost :  1.020683717727661   accuracy :  0.7155555486679077 val_acc:  0.6952000260353088 val_binary_acc 0.8827000260353088\n",
      "epoch :  446   cost :  1.0214131593704223   accuracy :  0.7133888602256775 val_acc:  0.6937999725341797 val_binary_acc 0.8830999732017517\n",
      "epoch :  447   cost :  1.0211914658546446   accuracy :  0.7164777517318726 val_acc:  0.6977999806404114 val_binary_acc 0.881600022315979\n",
      "epoch :  448   cost :  1.0211486101150513   accuracy :  0.7162555456161499 val_acc:  0.6965000033378601 val_binary_acc 0.879800021648407\n",
      "epoch :  449   cost :  1.0207744002342225   accuracy :  0.7179444432258606 val_acc:  0.6984999775886536 val_binary_acc 0.8812999725341797\n",
      "epoch :  450   cost :  1.0206114649772642   accuracy :  0.7167222499847412 val_acc:  0.6960999965667725 val_binary_acc 0.8801000118255615\n",
      "epoch :  451   cost :  1.0208072304725646   accuracy :  0.7177333235740662 val_acc:  0.6973000168800354 val_binary_acc 0.8830000162124634\n",
      "epoch :  452   cost :  1.0201430797576905   accuracy :  0.7176222205162048 val_acc:  0.6980000138282776 val_binary_acc 0.8809000253677368\n",
      "epoch :  453   cost :  1.0209962964057924   accuracy :  0.7180222272872925 val_acc:  0.697700023651123 val_binary_acc 0.8802000284194946\n",
      "epoch :  454   cost :  1.020560872554779   accuracy :  0.7175999879837036 val_acc:  0.6970999836921692 val_binary_acc 0.8797000050544739\n",
      "epoch :  455   cost :  1.0204634189605712   accuracy :  0.7179666757583618 val_acc:  0.6980000138282776 val_binary_acc 0.8820000290870667\n",
      "epoch :  456   cost :  1.0202289938926696   accuracy :  0.7170000076293945 val_acc:  0.6963000297546387 val_binary_acc 0.8827000260353088\n",
      "epoch :  457   cost :  1.020476734638214   accuracy :  0.7164666652679443 val_acc:  0.6972000002861023 val_binary_acc 0.8788999915122986\n",
      "epoch :  458   cost :  1.021221387386322   accuracy :  0.7173444628715515 val_acc:  0.6984999775886536 val_binary_acc 0.8826000094413757\n",
      "epoch :  459   cost :  1.0206308960914612   accuracy :  0.717377781867981 val_acc:  0.6984000205993652 val_binary_acc 0.8835999965667725\n",
      "epoch :  460   cost :  1.0200648427009584   accuracy :  0.7170110940933228 val_acc:  0.6972000002861023 val_binary_acc 0.8824999928474426\n",
      "epoch :  461   cost :  1.0199455976486207   accuracy :  0.718666672706604 val_acc:  0.6983000040054321 val_binary_acc 0.8801000118255615\n",
      "epoch :  462   cost :  1.0194440841674803   accuracy :  0.7190999984741211 val_acc:  0.6988000273704529 val_binary_acc 0.8852999806404114\n",
      "epoch :  463   cost :  1.0198430299758912   accuracy :  0.7175777554512024 val_acc:  0.6991000175476074 val_binary_acc 0.8805000185966492\n",
      "epoch :  464   cost :  1.0196567058563233   accuracy :  0.7184000015258789 val_acc:  0.6984999775886536 val_binary_acc 0.8810999989509583\n",
      "epoch :  465   cost :  1.0191215991973877   accuracy :  0.7189111113548279 val_acc:  0.6978999972343445 val_binary_acc 0.8827000260353088\n",
      "epoch :  466   cost :  1.0191786766052244   accuracy :  0.7191888689994812 val_acc:  0.6984000205993652 val_binary_acc 0.883400022983551\n",
      "epoch :  467   cost :  1.0191913485527038   accuracy :  0.7190444469451904 val_acc:  0.6991999745368958 val_binary_acc 0.8830000162124634\n",
      "epoch :  468   cost :  1.0190370321273803   accuracy :  0.7182666659355164 val_acc:  0.6970999836921692 val_binary_acc 0.8828999996185303\n",
      "epoch :  469   cost :  1.0195674419403076   accuracy :  0.7185999751091003 val_acc:  0.6980000138282776 val_binary_acc 0.8828999996185303\n",
      "epoch :  470   cost :  1.0192542195320131   accuracy :  0.7184222340583801 val_acc:  0.6995999813079834 val_binary_acc 0.879800021648407\n",
      "epoch :  471   cost :  1.019105327129364   accuracy :  0.7180888652801514 val_acc:  0.6991999745368958 val_binary_acc 0.8831999897956848\n",
      "epoch :  472   cost :  1.0197265148162842   accuracy :  0.7163333296775818 val_acc:  0.6966999769210815 val_binary_acc 0.8822000026702881\n",
      "epoch :  473   cost :  1.0196454286575318   accuracy :  0.7185111045837402 val_acc:  0.6972000002861023 val_binary_acc 0.8841000199317932\n",
      "epoch :  474   cost :  1.0188905596733093   accuracy :  0.7193666696548462 val_acc:  0.6991999745368958 val_binary_acc 0.8833000063896179\n",
      "epoch :  475   cost :  1.0185325384140014   accuracy :  0.7172666788101196 val_acc:  0.6952000260353088 val_binary_acc 0.8822000026702881\n",
      "epoch :  476   cost :  1.01975337266922   accuracy :  0.7184000015258789 val_acc:  0.6966999769210815 val_binary_acc 0.8805000185966492\n",
      "epoch :  477   cost :  1.0192538857460023   accuracy :  0.7171111106872559 val_acc:  0.6980000138282776 val_binary_acc 0.8837000131607056\n",
      "epoch :  478   cost :  1.0192587018013   accuracy :  0.7172666788101196 val_acc:  0.6947000026702881 val_binary_acc 0.8799999952316284\n",
      "epoch :  479   cost :  1.0196738123893738   accuracy :  0.7174444198608398 val_acc:  0.6963000297546387 val_binary_acc 0.8808000087738037\n",
      "epoch :  480   cost :  1.0198889017105102   accuracy :  0.7185555696487427 val_acc:  0.6972000002861023 val_binary_acc 0.8787999749183655\n",
      "epoch :  481   cost :  1.0198368549346926   accuracy :  0.718844473361969 val_acc:  0.6995000243186951 val_binary_acc 0.8827999830245972\n",
      "epoch :  482   cost :  1.0191099643707275   accuracy :  0.7189221978187561 val_acc:  0.698199987411499 val_binary_acc 0.8840000033378601\n",
      "epoch :  483   cost :  1.019224452972412   accuracy :  0.719011127948761 val_acc:  0.6988999843597412 val_binary_acc 0.8845000267028809\n",
      "epoch :  484   cost :  1.0184919476509093   accuracy :  0.7196666598320007 val_acc:  0.6978999972343445 val_binary_acc 0.8820000290870667\n",
      "epoch :  485   cost :  1.0184365034103393   accuracy :  0.7195000052452087 val_acc:  0.6996999979019165 val_binary_acc 0.8830000162124634\n",
      "epoch :  486   cost :  1.0187374114990233   accuracy :  0.7189777493476868 val_acc:  0.6996999979019165 val_binary_acc 0.8837000131607056\n",
      "epoch :  487   cost :  1.0180364012718202   accuracy :  0.7187111377716064 val_acc:  0.6996999979019165 val_binary_acc 0.8817999958992004\n",
      "epoch :  488   cost :  1.0186155676841735   accuracy :  0.7204999923706055 val_acc:  0.699400007724762 val_binary_acc 0.8809000253677368\n",
      "epoch :  489   cost :  1.0180027246475218   accuracy :  0.7181333303451538 val_acc:  0.6983000040054321 val_binary_acc 0.8841000199317932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  490   cost :  1.018744742870331   accuracy :  0.719355583190918 val_acc:  0.6983000040054321 val_binary_acc 0.8835999965667725\n",
      "epoch :  491   cost :  1.0185450315475466   accuracy :  0.7194888591766357 val_acc:  0.698199987411499 val_binary_acc 0.8809999823570251\n",
      "epoch :  492   cost :  1.0185403943061828   accuracy :  0.7187222242355347 val_acc:  0.6980000138282776 val_binary_acc 0.8788999915122986\n",
      "epoch :  493   cost :  1.0173370122909546   accuracy :  0.7195555567741394 val_acc:  0.6984000205993652 val_binary_acc 0.8848000168800354\n",
      "epoch :  494   cost :  1.017341887950897   accuracy :  0.7202444672584534 val_acc:  0.6980000138282776 val_binary_acc 0.8809999823570251\n",
      "epoch :  495   cost :  1.0170724511146545   accuracy :  0.7204111218452454 val_acc:  0.6995000243186951 val_binary_acc 0.8830999732017517\n",
      "epoch :  496   cost :  1.0176892161369322   accuracy :  0.7198777794837952 val_acc:  0.6992999911308289 val_binary_acc 0.8808000087738037\n",
      "epoch :  497   cost :  1.017189598083496   accuracy :  0.7196999788284302 val_acc:  0.699400007724762 val_binary_acc 0.8817999958992004\n",
      "epoch :  498   cost :  1.0174888372421265   accuracy :  0.7208555340766907 val_acc:  0.6992999911308289 val_binary_acc 0.8823000192642212\n",
      "epoch :  499   cost :  1.0172741413116455   accuracy :  0.7204222083091736 val_acc:  0.7006000280380249 val_binary_acc 0.8855999708175659\n",
      "epoch :  500   cost :  1.0169241070747377   accuracy :  0.720288872718811 val_acc:  0.6984000205993652 val_binary_acc 0.880299985408783\n",
      "epoch :  501   cost :  1.0169197201728821   accuracy :  0.720300018787384 val_acc:  0.7002000212669373 val_binary_acc 0.8823999762535095\n",
      "epoch :  502   cost :  1.0170125484466552   accuracy :  0.7208555340766907 val_acc:  0.6970999836921692 val_binary_acc 0.879800021648407\n",
      "epoch :  503   cost :  1.017079246044159   accuracy :  0.7209888696670532 val_acc:  0.6996999979019165 val_binary_acc 0.8817999958992004\n",
      "epoch :  504   cost :  1.0169354677200317   accuracy :  0.720644474029541 val_acc:  0.6990000009536743 val_binary_acc 0.8815000057220459\n",
      "epoch :  505   cost :  1.0174821257591247   accuracy :  0.7212666869163513 val_acc:  0.7001000046730042 val_binary_acc 0.8845000267028809\n",
      "epoch :  506   cost :  1.017282843589783   accuracy :  0.7209888696670532 val_acc:  0.6980000138282776 val_binary_acc 0.8820000290870667\n",
      "epoch :  507   cost :  1.0177181959152222   accuracy :  0.7194333076477051 val_acc:  0.698199987411499 val_binary_acc 0.8801000118255615\n",
      "epoch :  508   cost :  1.0175839066505432   accuracy :  0.7205444574356079 val_acc:  0.7001000046730042 val_binary_acc 0.8845999836921692\n",
      "epoch :  509   cost :  1.0169655323028564   accuracy :  0.7214000225067139 val_acc:  0.6991000175476074 val_binary_acc 0.8828999996185303\n",
      "epoch :  510   cost :  1.0173068523406983   accuracy :  0.7204777598381042 val_acc:  0.6991999745368958 val_binary_acc 0.8828999996185303\n",
      "epoch :  511   cost :  1.0171316385269165   accuracy :  0.7203666567802429 val_acc:  0.6987000107765198 val_binary_acc 0.8833000063896179\n",
      "epoch :  512   cost :  1.0169583678245544   accuracy :  0.7213777899742126 val_acc:  0.7006000280380249 val_binary_acc 0.8855999708175659\n",
      "epoch :  513   cost :  1.016808557510376   accuracy :  0.7200555801391602 val_acc:  0.6970999836921692 val_binary_acc 0.8799999952316284\n",
      "epoch :  514   cost :  1.0172141671180726   accuracy :  0.7208444476127625 val_acc:  0.6987000107765198 val_binary_acc 0.882099986076355\n",
      "epoch :  515   cost :  1.016828441619873   accuracy :  0.7222444415092468 val_acc:  0.697700023651123 val_binary_acc 0.8819000124931335\n",
      "epoch :  516   cost :  1.0159481406211852   accuracy :  0.7216444611549377 val_acc:  0.6998000144958496 val_binary_acc 0.8840000033378601\n",
      "epoch :  517   cost :  1.0163094639778139   accuracy :  0.7202333211898804 val_acc:  0.6965000033378601 val_binary_acc 0.8812000155448914\n",
      "epoch :  518   cost :  1.0165225744247437   accuracy :  0.7224555611610413 val_acc:  0.699999988079071 val_binary_acc 0.8816999793052673\n",
      "epoch :  519   cost :  1.0167717456817627   accuracy :  0.7199777960777283 val_acc:  0.6980999708175659 val_binary_acc 0.8838000297546387\n",
      "epoch :  520   cost :  1.0170073986053467   accuracy :  0.7208777666091919 val_acc:  0.6969000101089478 val_binary_acc 0.8817999958992004\n",
      "epoch :  521   cost :  1.0161682605743407   accuracy :  0.7223888635635376 val_acc:  0.699999988079071 val_binary_acc 0.8830999732017517\n",
      "epoch :  522   cost :  1.015929329395294   accuracy :  0.7216888666152954 val_acc:  0.7009000182151794 val_binary_acc 0.8835999965667725\n",
      "epoch :  523   cost :  1.0154353857040403   accuracy :  0.7231888771057129 val_acc:  0.7003999948501587 val_binary_acc 0.8842999935150146\n",
      "epoch :  524   cost :  1.0151070952415466   accuracy :  0.7224000096321106 val_acc:  0.699999988079071 val_binary_acc 0.8840000033378601\n",
      "epoch :  525   cost :  1.0160698175430298   accuracy :  0.7215222120285034 val_acc:  0.6990000009536743 val_binary_acc 0.8826000094413757\n",
      "epoch :  526   cost :  1.015802526473999   accuracy :  0.7231777906417847 val_acc:  0.699400007724762 val_binary_acc 0.8841000199317932\n",
      "epoch :  527   cost :  1.0151033282279969   accuracy :  0.7223444581031799 val_acc:  0.699999988079071 val_binary_acc 0.8834999799728394\n",
      "epoch :  528   cost :  1.0153904914855958   accuracy :  0.7224888801574707 val_acc:  0.699400007724762 val_binary_acc 0.8822000026702881\n",
      "epoch :  529   cost :  1.015057349205017   accuracy :  0.7224666476249695 val_acc:  0.7003999948501587 val_binary_acc 0.8823000192642212\n",
      "epoch :  530   cost :  1.014843463897705   accuracy :  0.7222222089767456 val_acc:  0.7002000212669373 val_binary_acc 0.8847000002861023\n",
      "epoch :  531   cost :  1.0155468702316284   accuracy :  0.7215222120285034 val_acc:  0.6967999935150146 val_binary_acc 0.8816999793052673\n",
      "epoch :  532   cost :  1.0165061235427857   accuracy :  0.7222444415092468 val_acc:  0.6987000107765198 val_binary_acc 0.8831999897956848\n",
      "epoch :  533   cost :  1.0155559062957764   accuracy :  0.7213888764381409 val_acc:  0.6991999745368958 val_binary_acc 0.8859000205993652\n",
      "epoch :  534   cost :  1.01484295129776   accuracy :  0.722955584526062 val_acc:  0.7005000114440918 val_binary_acc 0.8841999769210815\n",
      "epoch :  535   cost :  1.014596903324127   accuracy :  0.722611129283905 val_acc:  0.6992999911308289 val_binary_acc 0.8838000297546387\n",
      "epoch :  536   cost :  1.014936399459839   accuracy :  0.7237555384635925 val_acc:  0.7006999850273132 val_binary_acc 0.8855000138282776\n",
      "epoch :  537   cost :  1.0148510575294496   accuracy :  0.7232778072357178 val_acc:  0.701200008392334 val_binary_acc 0.8835999965667725\n",
      "epoch :  538   cost :  1.0147168636322024   accuracy :  0.7223333120346069 val_acc:  0.6998000144958496 val_binary_acc 0.8845000267028809\n",
      "epoch :  539   cost :  1.0148037672042847   accuracy :  0.7235222458839417 val_acc:  0.6995000243186951 val_binary_acc 0.8848999738693237\n",
      "epoch :  540   cost :  1.0156831979751586   accuracy :  0.719355583190918 val_acc:  0.6962000131607056 val_binary_acc 0.8831999897956848\n",
      "epoch :  541   cost :  1.0159479737281798   accuracy :  0.7220666408538818 val_acc:  0.6966999769210815 val_binary_acc 0.8823999762535095\n",
      "epoch :  542   cost :  1.0146049261093142   accuracy :  0.723455548286438 val_acc:  0.6996999979019165 val_binary_acc 0.8830000162124634\n",
      "epoch :  543   cost :  1.0146188020706177   accuracy :  0.7224110960960388 val_acc:  0.6988999843597412 val_binary_acc 0.8841999769210815\n",
      "epoch :  544   cost :  1.0145765542984009   accuracy :  0.723455548286438 val_acc:  0.7006000280380249 val_binary_acc 0.8842999935150146\n",
      "epoch :  545   cost :  1.0147831082344054   accuracy :  0.7223777770996094 val_acc:  0.6980000138282776 val_binary_acc 0.8841000199317932\n",
      "epoch :  546   cost :  1.0149494886398316   accuracy :  0.7224888801574707 val_acc:  0.6991999745368958 val_binary_acc 0.8827999830245972\n",
      "epoch :  547   cost :  1.0141327261924744   accuracy :  0.7229999899864197 val_acc:  0.6973999738693237 val_binary_acc 0.8840000033378601\n",
      "epoch :  548   cost :  1.0149295806884766   accuracy :  0.7219222187995911 val_acc:  0.6991999745368958 val_binary_acc 0.8845999836921692\n",
      "epoch :  549   cost :  1.0146712422370912   accuracy :  0.722611129283905 val_acc:  0.699999988079071 val_binary_acc 0.8833000063896179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  550   cost :  1.0141220569610594   accuracy :  0.7238222360610962 val_acc:  0.7003999948501587 val_binary_acc 0.8840000033378601\n",
      "epoch :  551   cost :  1.0135740518569947   accuracy :  0.7243000268936157 val_acc:  0.6995999813079834 val_binary_acc 0.8831999897956848\n",
      "epoch :  552   cost :  1.0132455587387086   accuracy :  0.7245000004768372 val_acc:  0.6992999911308289 val_binary_acc 0.8823000192642212\n",
      "epoch :  553   cost :  1.0134438514709474   accuracy :  0.7237333059310913 val_acc:  0.7002000212669373 val_binary_acc 0.8841999769210815\n",
      "epoch :  554   cost :  1.013838541507721   accuracy :  0.7224555611610413 val_acc:  0.7005000114440918 val_binary_acc 0.8847000002861023\n",
      "epoch :  555   cost :  1.014474618434906   accuracy :  0.7239999771118164 val_acc:  0.699999988079071 val_binary_acc 0.885200023651123\n",
      "epoch :  556   cost :  1.0135159134864806   accuracy :  0.7241111397743225 val_acc:  0.7002000212669373 val_binary_acc 0.8835999965667725\n",
      "epoch :  557   cost :  1.0134424090385437   accuracy :  0.7239999771118164 val_acc:  0.7009000182151794 val_binary_acc 0.8835999965667725\n",
      "epoch :  558   cost :  1.0135951519012452   accuracy :  0.7235444188117981 val_acc:  0.7006999850273132 val_binary_acc 0.8828999996185303\n",
      "epoch :  559   cost :  1.0132720708847045   accuracy :  0.7248888611793518 val_acc:  0.7009000182151794 val_binary_acc 0.8859000205993652\n",
      "epoch :  560   cost :  1.0137849926948548   accuracy :  0.7251333594322205 val_acc:  0.7014999985694885 val_binary_acc 0.8851000070571899\n",
      "epoch :  561   cost :  1.0127368211746217   accuracy :  0.7264222502708435 val_acc:  0.7024000287055969 val_binary_acc 0.8853999972343445\n",
      "epoch :  562   cost :  1.0115976095199586   accuracy :  0.7270222306251526 val_acc:  0.7031000256538391 val_binary_acc 0.8859000205993652\n",
      "epoch :  563   cost :  1.0108318567276002   accuracy :  0.7273889183998108 val_acc:  0.7026000022888184 val_binary_acc 0.8867999911308289\n",
      "epoch :  564   cost :  1.0107080221176146   accuracy :  0.7273777723312378 val_acc:  0.7021999955177307 val_binary_acc 0.8842999935150146\n",
      "epoch :  565   cost :  1.0107880234718323   accuracy :  0.726877748966217 val_acc:  0.7021999955177307 val_binary_acc 0.8853999972343445\n",
      "epoch :  566   cost :  1.0108139634132387   accuracy :  0.7265444397926331 val_acc:  0.7021999955177307 val_binary_acc 0.8848999738693237\n",
      "epoch :  567   cost :  1.0109748601913453   accuracy :  0.7268333435058594 val_acc:  0.7037000060081482 val_binary_acc 0.8867999911308289\n",
      "epoch :  568   cost :  1.0108200073242188   accuracy :  0.727055549621582 val_acc:  0.7042999863624573 val_binary_acc 0.8862000107765198\n",
      "epoch :  569   cost :  1.0097986698150636   accuracy :  0.7276222109794617 val_acc:  0.7050999999046326 val_binary_acc 0.8870000243186951\n",
      "epoch :  570   cost :  1.0101831436157227   accuracy :  0.7276555299758911 val_acc:  0.7056000232696533 val_binary_acc 0.8877999782562256\n",
      "epoch :  571   cost :  1.0098678350448609   accuracy :  0.7292888760566711 val_acc:  0.7041000127792358 val_binary_acc 0.8862000107765198\n",
      "epoch :  572   cost :  1.009316611289978   accuracy :  0.7280555367469788 val_acc:  0.7045000195503235 val_binary_acc 0.8871999979019165\n",
      "epoch :  573   cost :  1.0098499059677124   accuracy :  0.7286111116409302 val_acc:  0.7045999765396118 val_binary_acc 0.8849999904632568\n",
      "epoch :  574   cost :  1.0095807433128356   accuracy :  0.7283444404602051 val_acc:  0.7050999999046326 val_binary_acc 0.8877999782562256\n",
      "epoch :  575   cost :  1.0088612079620363   accuracy :  0.7289333343505859 val_acc:  0.704200029373169 val_binary_acc 0.8867999911308289\n",
      "epoch :  576   cost :  1.009355103969574   accuracy :  0.7288444638252258 val_acc:  0.7045999765396118 val_binary_acc 0.8870000243186951\n",
      "epoch :  577   cost :  1.0088585019111633   accuracy :  0.7295555472373962 val_acc:  0.7075999975204468 val_binary_acc 0.886900007724762\n",
      "epoch :  578   cost :  1.0085207581520081   accuracy :  0.7295222282409668 val_acc:  0.7067000269889832 val_binary_acc 0.8859999775886536\n",
      "epoch :  579   cost :  1.0082805037498472   accuracy :  0.7303000092506409 val_acc:  0.705299973487854 val_binary_acc 0.8876000046730042\n",
      "epoch :  580   cost :  1.0082494497299195   accuracy :  0.7285222411155701 val_acc:  0.7031000256538391 val_binary_acc 0.887499988079071\n",
      "epoch :  581   cost :  1.009031057357788   accuracy :  0.7293888926506042 val_acc:  0.7049999833106995 val_binary_acc 0.8859000205993652\n",
      "epoch :  582   cost :  1.0092758774757384   accuracy :  0.728600025177002 val_acc:  0.7049999833106995 val_binary_acc 0.8870999813079834\n",
      "epoch :  583   cost :  1.0095803380012511   accuracy :  0.7283777594566345 val_acc:  0.7056000232696533 val_binary_acc 0.8883000016212463\n",
      "epoch :  584   cost :  1.0088395357131958   accuracy :  0.7289000153541565 val_acc:  0.705299973487854 val_binary_acc 0.8877000212669373\n",
      "epoch :  585   cost :  1.0085827112197876   accuracy :  0.7299110889434814 val_acc:  0.7056000232696533 val_binary_acc 0.8877999782562256\n",
      "epoch :  586   cost :  1.0088721990585325   accuracy :  0.728855550289154 val_acc:  0.7049000263214111 val_binary_acc 0.8867999911308289\n",
      "epoch :  587   cost :  1.0087953686714173   accuracy :  0.7298555374145508 val_acc:  0.7045999765396118 val_binary_acc 0.8870999813079834\n",
      "epoch :  588   cost :  1.0092949509620668   accuracy :  0.7282111048698425 val_acc:  0.7049999833106995 val_binary_acc 0.8859999775886536\n",
      "epoch :  589   cost :  1.0089965224266053   accuracy :  0.7294889092445374 val_acc:  0.7035999894142151 val_binary_acc 0.8873999714851379\n",
      "epoch :  590   cost :  1.0088212609291076   accuracy :  0.7291444540023804 val_acc:  0.7038000226020813 val_binary_acc 0.8859999775886536\n",
      "epoch :  591   cost :  1.0083888530731202   accuracy :  0.7301333546638489 val_acc:  0.7052000164985657 val_binary_acc 0.886900007724762\n",
      "epoch :  592   cost :  1.0086668968200683   accuracy :  0.729200005531311 val_acc:  0.7049000263214111 val_binary_acc 0.8881000280380249\n",
      "epoch :  593   cost :  1.0079810619354248   accuracy :  0.7311000227928162 val_acc:  0.7055000066757202 val_binary_acc 0.8855999708175659\n",
      "epoch :  594   cost :  1.0075944900512694   accuracy :  0.7307666540145874 val_acc:  0.7078999876976013 val_binary_acc 0.8884999752044678\n",
      "epoch :  595   cost :  1.007739746570587   accuracy :  0.7306110858917236 val_acc:  0.7063999772071838 val_binary_acc 0.8881999850273132\n",
      "epoch :  596   cost :  1.0075361490249632   accuracy :  0.7301999926567078 val_acc:  0.705299973487854 val_binary_acc 0.8858000040054321\n",
      "epoch :  597   cost :  1.007641327381134   accuracy :  0.7309444546699524 val_acc:  0.70660001039505 val_binary_acc 0.8871999979019165\n",
      "epoch :  598   cost :  1.0075609803199768   accuracy :  0.7305444478988647 val_acc:  0.7057999968528748 val_binary_acc 0.8863000273704529\n",
      "epoch :  599   cost :  1.0077215433120728   accuracy :  0.7299444675445557 val_acc:  0.7074999809265137 val_binary_acc 0.8881999850273132\n",
      "epoch :  600   cost :  1.0076045274734498   accuracy :  0.7304111123085022 val_acc:  0.7056999802589417 val_binary_acc 0.8870000243186951\n",
      "epoch :  601   cost :  1.007803416252136   accuracy :  0.730222225189209 val_acc:  0.7045999765396118 val_binary_acc 0.8866000175476074\n",
      "epoch :  602   cost :  1.0082751154899599   accuracy :  0.7292888760566711 val_acc:  0.7050999999046326 val_binary_acc 0.8877999782562256\n",
      "epoch :  603   cost :  1.0095537066459657   accuracy :  0.72971111536026 val_acc:  0.7064999938011169 val_binary_acc 0.8885999917984009\n",
      "epoch :  604   cost :  1.0089061617851258   accuracy :  0.7301333546638489 val_acc:  0.7057999968528748 val_binary_acc 0.8859000205993652\n",
      "epoch :  605   cost :  1.0080300390720367   accuracy :  0.7305111289024353 val_acc:  0.707099974155426 val_binary_acc 0.8892999887466431\n",
      "epoch :  606   cost :  1.008036732673645   accuracy :  0.7297999858856201 val_acc:  0.7049000263214111 val_binary_acc 0.8858000040054321\n",
      "epoch :  607   cost :  1.0081574678421021   accuracy :  0.7299110889434814 val_acc:  0.7053999900817871 val_binary_acc 0.8870000243186951\n",
      "epoch :  608   cost :  1.0079206585884093   accuracy :  0.7299555540084839 val_acc:  0.7053999900817871 val_binary_acc 0.887499988079071\n",
      "epoch :  609   cost :  1.0075738906860352   accuracy :  0.7303110957145691 val_acc:  0.7056999802589417 val_binary_acc 0.8873000144958496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  610   cost :  1.0073816180229187   accuracy :  0.7299333214759827 val_acc:  0.70660001039505 val_binary_acc 0.887499988079071\n",
      "epoch :  611   cost :  1.0078292131423952   accuracy :  0.7298444509506226 val_acc:  0.7056000232696533 val_binary_acc 0.8888999819755554\n",
      "epoch :  612   cost :  1.0082310557365417   accuracy :  0.7273666858673096 val_acc:  0.7034000158309937 val_binary_acc 0.886900007724762\n",
      "epoch :  613   cost :  1.0084540486335754   accuracy :  0.7305999994277954 val_acc:  0.7050999999046326 val_binary_acc 0.8871999979019165\n",
      "epoch :  614   cost :  1.0074660003185272   accuracy :  0.7305222153663635 val_acc:  0.7045000195503235 val_binary_acc 0.8876000046730042\n",
      "epoch :  615   cost :  1.0066230058670045   accuracy :  0.731855571269989 val_acc:  0.7045000195503235 val_binary_acc 0.8865000009536743\n",
      "epoch :  616   cost :  1.007148015499115   accuracy :  0.7308222055435181 val_acc:  0.7052000164985657 val_binary_acc 0.8873999714851379\n",
      "epoch :  617   cost :  1.0063834905624391   accuracy :  0.7310444712638855 val_acc:  0.704800009727478 val_binary_acc 0.8867999911308289\n",
      "epoch :  618   cost :  1.0069679141044616   accuracy :  0.7308444380760193 val_acc:  0.7045000195503235 val_binary_acc 0.8881000280380249\n",
      "epoch :  619   cost :  1.006781232357025   accuracy :  0.7308333516120911 val_acc:  0.7053999900817871 val_binary_acc 0.8870999813079834\n",
      "epoch :  620   cost :  1.0067259311676027   accuracy :  0.7317222356796265 val_acc:  0.7049000263214111 val_binary_acc 0.8867999911308289\n",
      "epoch :  621   cost :  1.006313157081604   accuracy :  0.7321222424507141 val_acc:  0.7088000178337097 val_binary_acc 0.8877999782562256\n",
      "epoch :  622   cost :  1.006207263469696   accuracy :  0.7320555448532104 val_acc:  0.7064999938011169 val_binary_acc 0.8880000114440918\n",
      "epoch :  623   cost :  1.0069875240325927   accuracy :  0.7317333221435547 val_acc:  0.7055000066757202 val_binary_acc 0.8867999911308289\n",
      "epoch :  624   cost :  1.0070760607719422   accuracy :  0.7319444417953491 val_acc:  0.7067999839782715 val_binary_acc 0.8873999714851379\n",
      "epoch :  625   cost :  1.0064225912094116   accuracy :  0.731166660785675 val_acc:  0.7035999894142151 val_binary_acc 0.8870999813079834\n",
      "epoch :  626   cost :  1.0063703179359436   accuracy :  0.7315000295639038 val_acc:  0.707099974155426 val_binary_acc 0.8877000212669373\n",
      "epoch :  627   cost :  1.0059359788894653   accuracy :  0.7312889099121094 val_acc:  0.7057999968528748 val_binary_acc 0.8885999917984009\n",
      "epoch :  628   cost :  1.0064948320388796   accuracy :  0.7320444583892822 val_acc:  0.7049999833106995 val_binary_acc 0.8862000107765198\n",
      "epoch :  629   cost :  1.0065818905830384   accuracy :  0.731688916683197 val_acc:  0.7067999839782715 val_binary_acc 0.8867999911308289\n",
      "epoch :  630   cost :  1.0060156345367433   accuracy :  0.7314555644989014 val_acc:  0.7063000202178955 val_binary_acc 0.8877999782562256\n",
      "epoch :  631   cost :  1.0061528742313386   accuracy :  0.732188880443573 val_acc:  0.7046999931335449 val_binary_acc 0.8885999917984009\n",
      "epoch :  632   cost :  1.0057907462120057   accuracy :  0.7322555780410767 val_acc:  0.7053999900817871 val_binary_acc 0.8873000144958496\n",
      "epoch :  633   cost :  1.0060051262378693   accuracy :  0.7313222289085388 val_acc:  0.7057999968528748 val_binary_acc 0.8883000016212463\n",
      "epoch :  634   cost :  1.0061976909637451   accuracy :  0.7319444417953491 val_acc:  0.7074999809265137 val_binary_acc 0.887499988079071\n",
      "epoch :  635   cost :  1.0058836102485658   accuracy :  0.7314666509628296 val_acc:  0.7042999863624573 val_binary_acc 0.8877999782562256\n",
      "epoch :  636   cost :  1.0058500289916992   accuracy :  0.7307778000831604 val_acc:  0.705299973487854 val_binary_acc 0.8881999850273132\n",
      "epoch :  637   cost :  1.0063025593757629   accuracy :  0.7314888834953308 val_acc:  0.7041000127792358 val_binary_acc 0.8866999745368958\n",
      "epoch :  638   cost :  1.0067973613739014   accuracy :  0.7306110858917236 val_acc:  0.7063000202178955 val_binary_acc 0.887499988079071\n",
      "epoch :  639   cost :  1.0063196539878845   accuracy :  0.7325778007507324 val_acc:  0.7067000269889832 val_binary_acc 0.8884000182151794\n",
      "epoch :  640   cost :  1.0060174107551574   accuracy :  0.7318666577339172 val_acc:  0.7056999802589417 val_binary_acc 0.8870000243186951\n",
      "epoch :  641   cost :  1.0057007789611816   accuracy :  0.7332888841629028 val_acc:  0.7050999999046326 val_binary_acc 0.8877000212669373\n",
      "epoch :  642   cost :  1.0058189988136292   accuracy :  0.7331777811050415 val_acc:  0.7052000164985657 val_binary_acc 0.8877999782562256\n",
      "epoch :  643   cost :  1.0057548880577087   accuracy :  0.7319555282592773 val_acc:  0.7059000134468079 val_binary_acc 0.8867999911308289\n",
      "epoch :  644   cost :  1.005608540773392   accuracy :  0.7322444319725037 val_acc:  0.7049000263214111 val_binary_acc 0.887499988079071\n",
      "epoch :  645   cost :  1.0049304842948912   accuracy :  0.7326333522796631 val_acc:  0.705299973487854 val_binary_acc 0.8859999775886536\n",
      "epoch :  646   cost :  1.0051055729389191   accuracy :  0.7331777811050415 val_acc:  0.7062000036239624 val_binary_acc 0.887499988079071\n",
      "epoch :  647   cost :  1.0050245642662048   accuracy :  0.7333666682243347 val_acc:  0.7050999999046326 val_binary_acc 0.8870000243186951\n",
      "epoch :  648   cost :  1.0047945857048035   accuracy :  0.7329000234603882 val_acc:  0.7064999938011169 val_binary_acc 0.8877999782562256\n",
      "epoch :  649   cost :  1.0050735414028167   accuracy :  0.7339555621147156 val_acc:  0.7073000073432922 val_binary_acc 0.8870999813079834\n",
      "epoch :  650   cost :  1.00528524518013   accuracy :  0.7326333522796631 val_acc:  0.7073000073432922 val_binary_acc 0.8891000151634216\n",
      "epoch :  651   cost :  1.0050699234008789   accuracy :  0.7325888872146606 val_acc:  0.7074999809265137 val_binary_acc 0.8885999917984009\n",
      "epoch :  652   cost :  1.0055935025215148   accuracy :  0.7321666479110718 val_acc:  0.7064999938011169 val_binary_acc 0.8883000016212463\n",
      "epoch :  653   cost :  1.0054792702198028   accuracy :  0.7320555448532104 val_acc:  0.7044000029563904 val_binary_acc 0.8859000205993652\n",
      "epoch :  654   cost :  1.0052997827529906   accuracy :  0.7330333590507507 val_acc:  0.7064999938011169 val_binary_acc 0.8866999745368958\n",
      "epoch :  655   cost :  1.0050674200057983   accuracy :  0.7331888675689697 val_acc:  0.7074999809265137 val_binary_acc 0.8884999752044678\n",
      "epoch :  656   cost :  1.0050015568733215   accuracy :  0.7329666614532471 val_acc:  0.7063000202178955 val_binary_acc 0.8873000144958496\n",
      "epoch :  657   cost :  1.0056031107902526   accuracy :  0.7312999963760376 val_acc:  0.7041000127792358 val_binary_acc 0.8867999911308289\n",
      "epoch :  658   cost :  1.00557256937027   accuracy :  0.732699990272522 val_acc:  0.7049000263214111 val_binary_acc 0.8878999948501587\n",
      "epoch :  659   cost :  1.004653763771057   accuracy :  0.732366681098938 val_acc:  0.7063000202178955 val_binary_acc 0.8863999843597412\n",
      "epoch :  660   cost :  1.0047631740570069   accuracy :  0.7337777614593506 val_acc:  0.7046999931335449 val_binary_acc 0.8870999813079834\n",
      "epoch :  661   cost :  1.0043564081192016   accuracy :  0.7325666546821594 val_acc:  0.7034000158309937 val_binary_acc 0.8859999775886536\n",
      "epoch :  662   cost :  1.005003398656845   accuracy :  0.7338666915893555 val_acc:  0.7069000005722046 val_binary_acc 0.8867999911308289\n",
      "epoch :  663   cost :  1.0049445152282714   accuracy :  0.733644425868988 val_acc:  0.7064999938011169 val_binary_acc 0.8870999813079834\n",
      "epoch :  664   cost :  1.0047697365283967   accuracy :  0.7329888939857483 val_acc:  0.7056000232696533 val_binary_acc 0.8870999813079834\n",
      "epoch :  665   cost :  1.0044637858867644   accuracy :  0.7335000038146973 val_acc:  0.7045999765396118 val_binary_acc 0.8873999714851379\n",
      "epoch :  666   cost :  1.0048584699630738   accuracy :  0.7331777811050415 val_acc:  0.7049999833106995 val_binary_acc 0.8873000144958496\n",
      "epoch :  667   cost :  1.0046968221664427   accuracy :  0.7338666915893555 val_acc:  0.7064999938011169 val_binary_acc 0.8880000114440918\n",
      "epoch :  668   cost :  1.0044555604457854   accuracy :  0.7325111031532288 val_acc:  0.704800009727478 val_binary_acc 0.8863999843597412\n",
      "epoch :  669   cost :  1.0051609694957733   accuracy :  0.7335110902786255 val_acc:  0.705299973487854 val_binary_acc 0.8877999782562256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  670   cost :  1.0050813376903533   accuracy :  0.7319889068603516 val_acc:  0.7044000029563904 val_binary_acc 0.8873999714851379\n",
      "epoch :  671   cost :  1.0056499600410462   accuracy :  0.7330555319786072 val_acc:  0.7055000066757202 val_binary_acc 0.8867999911308289\n",
      "epoch :  672   cost :  1.0049394965171814   accuracy :  0.7329555749893188 val_acc:  0.704800009727478 val_binary_acc 0.8866999745368958\n",
      "epoch :  673   cost :  1.0044254660606386   accuracy :  0.7344222068786621 val_acc:  0.7077999711036682 val_binary_acc 0.8885999917984009\n",
      "epoch :  674   cost :  1.003769117593765   accuracy :  0.7342888712882996 val_acc:  0.7067999839782715 val_binary_acc 0.8881000280380249\n",
      "epoch :  675   cost :  1.0035823464393616   accuracy :  0.7338444590568542 val_acc:  0.7050999999046326 val_binary_acc 0.886900007724762\n",
      "epoch :  676   cost :  1.0042307317256927   accuracy :  0.732877790927887 val_acc:  0.7063000202178955 val_binary_acc 0.8853999972343445\n",
      "epoch :  677   cost :  1.0043093264102936   accuracy :  0.7337333559989929 val_acc:  0.7057999968528748 val_binary_acc 0.8866999745368958\n",
      "epoch :  678   cost :  1.0039641380310058   accuracy :  0.734333336353302 val_acc:  0.7049000263214111 val_binary_acc 0.8866999745368958\n",
      "epoch :  679   cost :  1.0038367927074434   accuracy :  0.7341889142990112 val_acc:  0.7045999765396118 val_binary_acc 0.8876000046730042\n",
      "epoch :  680   cost :  1.0039765954017639   accuracy :  0.7344222068786621 val_acc:  0.7050999999046326 val_binary_acc 0.8866999745368958\n",
      "epoch :  681   cost :  1.0038358509540557   accuracy :  0.7344222068786621 val_acc:  0.7042999863624573 val_binary_acc 0.8866999745368958\n",
      "epoch :  682   cost :  1.003773844242096   accuracy :  0.7341333627700806 val_acc:  0.7067999839782715 val_binary_acc 0.8881999850273132\n",
      "epoch :  683   cost :  1.0036948144435884   accuracy :  0.7337222099304199 val_acc:  0.7049000263214111 val_binary_acc 0.8885999917984009\n",
      "epoch :  684   cost :  1.0037247121334076   accuracy :  0.7353110909461975 val_acc:  0.7064999938011169 val_binary_acc 0.8881000280380249\n",
      "epoch :  685   cost :  1.0031668961048126   accuracy :  0.7342333197593689 val_acc:  0.7067000269889832 val_binary_acc 0.8889999985694885\n",
      "epoch :  686   cost :  1.0033389747142791   accuracy :  0.7347333431243896 val_acc:  0.7057999968528748 val_binary_acc 0.8888000249862671\n",
      "epoch :  687   cost :  1.0028867959976195   accuracy :  0.7348999977111816 val_acc:  0.70660001039505 val_binary_acc 0.8878999948501587\n",
      "epoch :  688   cost :  1.0033928215503691   accuracy :  0.7342555522918701 val_acc:  0.7056999802589417 val_binary_acc 0.8877000212669373\n",
      "epoch :  689   cost :  1.0032279014587404   accuracy :  0.7345777750015259 val_acc:  0.7059000134468079 val_binary_acc 0.8880000114440918\n",
      "epoch :  690   cost :  1.0031699657440185   accuracy :  0.7342555522918701 val_acc:  0.7057999968528748 val_binary_acc 0.8863000273704529\n",
      "epoch :  691   cost :  1.0031005144119263   accuracy :  0.7347999811172485 val_acc:  0.7067999839782715 val_binary_acc 0.8880000114440918\n",
      "epoch :  692   cost :  1.0029610216617586   accuracy :  0.7337889075279236 val_acc:  0.7056000232696533 val_binary_acc 0.8863999843597412\n",
      "epoch :  693   cost :  1.0038946270942688   accuracy :  0.732711136341095 val_acc:  0.7049000263214111 val_binary_acc 0.8881999850273132\n",
      "epoch :  694   cost :  1.004414290189743   accuracy :  0.7339110970497131 val_acc:  0.7060999870300293 val_binary_acc 0.8889999985694885\n",
      "epoch :  695   cost :  1.0033996641635894   accuracy :  0.7345666885375977 val_acc:  0.7045999765396118 val_binary_acc 0.886900007724762\n",
      "epoch :  696   cost :  1.0031859815120696   accuracy :  0.7339555621147156 val_acc:  0.7056999802589417 val_binary_acc 0.8881999850273132\n",
      "epoch :  697   cost :  1.0034363269805908   accuracy :  0.7342555522918701 val_acc:  0.70660001039505 val_binary_acc 0.8883000016212463\n",
      "epoch :  698   cost :  1.003079116344452   accuracy :  0.7348889112472534 val_acc:  0.7067000269889832 val_binary_acc 0.8885999917984009\n",
      "epoch :  699   cost :  1.0028365075588226   accuracy :  0.735188901424408 val_acc:  0.7069000005722046 val_binary_acc 0.8877000212669373\n",
      "epoch :  700   cost :  1.0029192984104158   accuracy :  0.7351444363594055 val_acc:  0.7074999809265137 val_binary_acc 0.8885999917984009\n",
      "epoch :  701   cost :  1.0035305202007294   accuracy :  0.7347221970558167 val_acc:  0.7052000164985657 val_binary_acc 0.8877999782562256\n",
      "epoch :  702   cost :  1.003010606765747   accuracy :  0.7356777787208557 val_acc:  0.7057999968528748 val_binary_acc 0.8880000114440918\n",
      "epoch :  703   cost :  1.0027140259742737   accuracy :  0.7350666522979736 val_acc:  0.7049999833106995 val_binary_acc 0.8881999850273132\n",
      "epoch :  704   cost :  1.0027464509010315   accuracy :  0.7356333136558533 val_acc:  0.7069000005722046 val_binary_acc 0.8881999850273132\n",
      "epoch :  705   cost :  1.0028845846652985   accuracy :  0.7347333431243896 val_acc:  0.7053999900817871 val_binary_acc 0.8881999850273132\n",
      "epoch :  706   cost :  1.0036376595497134   accuracy :  0.7336333394050598 val_acc:  0.7044000029563904 val_binary_acc 0.8889999985694885\n",
      "epoch :  707   cost :  1.0034025549888612   accuracy :  0.7350000143051147 val_acc:  0.707099974155426 val_binary_acc 0.8881999850273132\n",
      "epoch :  708   cost :  1.002521550655365   accuracy :  0.7355666756629944 val_acc:  0.7056000232696533 val_binary_acc 0.8866999745368958\n",
      "epoch :  709   cost :  1.002780020236969   accuracy :  0.7353666424751282 val_acc:  0.7071999907493591 val_binary_acc 0.8883000016212463\n",
      "epoch :  710   cost :  1.0022699594497682   accuracy :  0.7355222105979919 val_acc:  0.7059000134468079 val_binary_acc 0.8877000212669373\n",
      "epoch :  711   cost :  1.002433305978775   accuracy :  0.7353333234786987 val_acc:  0.7056000232696533 val_binary_acc 0.8885999917984009\n",
      "epoch :  712   cost :  1.003330373764038   accuracy :  0.734666645526886 val_acc:  0.7038999795913696 val_binary_acc 0.8884000182151794\n",
      "epoch :  713   cost :  1.003359866142273   accuracy :  0.7343666553497314 val_acc:  0.7045000195503235 val_binary_acc 0.887499988079071\n",
      "epoch :  714   cost :  1.0033956587314605   accuracy :  0.7343000173568726 val_acc:  0.7059999704360962 val_binary_acc 0.8867999911308289\n",
      "epoch :  715   cost :  1.002660620212555   accuracy :  0.7355999946594238 val_acc:  0.7059999704360962 val_binary_acc 0.8881000280380249\n",
      "epoch :  716   cost :  1.0024410784244537   accuracy :  0.7348111271858215 val_acc:  0.7064999938011169 val_binary_acc 0.8888000249862671\n",
      "epoch :  717   cost :  1.0031252324581148   accuracy :  0.7354221940040588 val_acc:  0.7057999968528748 val_binary_acc 0.886900007724762\n",
      "epoch :  718   cost :  1.002651745080948   accuracy :  0.7352666854858398 val_acc:  0.7062000036239624 val_binary_acc 0.8873999714851379\n",
      "epoch :  719   cost :  1.0022555112838745   accuracy :  0.7357777953147888 val_acc:  0.7080000042915344 val_binary_acc 0.888700008392334\n",
      "epoch :  720   cost :  1.0023288726806643   accuracy :  0.7351444363594055 val_acc:  0.7060999870300293 val_binary_acc 0.8877000212669373\n",
      "epoch :  721   cost :  1.0018255710601807   accuracy :  0.7350444197654724 val_acc:  0.7067999839782715 val_binary_acc 0.8883000016212463\n",
      "epoch :  722   cost :  1.0024306356906891   accuracy :  0.7358111143112183 val_acc:  0.7070000171661377 val_binary_acc 0.8880000114440918\n",
      "epoch :  723   cost :  1.0026685118675231   accuracy :  0.7353777885437012 val_acc:  0.7056000232696533 val_binary_acc 0.8881000280380249\n",
      "epoch :  724   cost :  1.0027517318725585   accuracy :  0.7352333068847656 val_acc:  0.7053999900817871 val_binary_acc 0.8880000114440918\n",
      "epoch :  725   cost :  1.0032694160938265   accuracy :  0.7354666590690613 val_acc:  0.704800009727478 val_binary_acc 0.8883000016212463\n",
      "epoch :  726   cost :  1.002723753452301   accuracy :  0.7350444197654724 val_acc:  0.7070000171661377 val_binary_acc 0.8865000009536743\n",
      "epoch :  727   cost :  1.0024853110313416   accuracy :  0.7354111075401306 val_acc:  0.7071999907493591 val_binary_acc 0.88919997215271\n",
      "epoch :  728   cost :  1.0020883023738862   accuracy :  0.7356555461883545 val_acc:  0.7073000073432922 val_binary_acc 0.887499988079071\n",
      "epoch :  729   cost :  1.002321469783783   accuracy :  0.7333333492279053 val_acc:  0.7038999795913696 val_binary_acc 0.885200023651123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  730   cost :  1.0029101550579074   accuracy :  0.7347555756568909 val_acc:  0.7055000066757202 val_binary_acc 0.8876000046730042\n",
      "epoch :  731   cost :  1.0030144155025484   accuracy :  0.7354888916015625 val_acc:  0.7056000232696533 val_binary_acc 0.8880000114440918\n",
      "epoch :  732   cost :  1.002393639087677   accuracy :  0.7351111173629761 val_acc:  0.7057999968528748 val_binary_acc 0.887499988079071\n",
      "epoch :  733   cost :  1.0021904706954954   accuracy :  0.7357110977172852 val_acc:  0.7059999704360962 val_binary_acc 0.8878999948501587\n",
      "epoch :  734   cost :  1.0021107614040374   accuracy :  0.736311137676239 val_acc:  0.7059000134468079 val_binary_acc 0.8878999948501587\n",
      "epoch :  735   cost :  1.0013483464717865   accuracy :  0.7372000217437744 val_acc:  0.7081999778747559 val_binary_acc 0.8892999887466431\n",
      "epoch :  736   cost :  1.0009911715984345   accuracy :  0.7373889088630676 val_acc:  0.7081999778747559 val_binary_acc 0.8876000046730042\n",
      "epoch :  737   cost :  1.001066941022873   accuracy :  0.7360888719558716 val_acc:  0.7074000239372253 val_binary_acc 0.8880000114440918\n",
      "epoch :  738   cost :  1.0013595461845397   accuracy :  0.7366111278533936 val_acc:  0.7078999876976013 val_binary_acc 0.8889999985694885\n",
      "epoch :  739   cost :  1.0014712810516357   accuracy :  0.7366333603858948 val_acc:  0.7081000208854675 val_binary_acc 0.8888000249862671\n",
      "epoch :  740   cost :  1.0015663087368014   accuracy :  0.7363666892051697 val_acc:  0.7063000202178955 val_binary_acc 0.8888000249862671\n",
      "epoch :  741   cost :  1.001368486881256   accuracy :  0.7367666959762573 val_acc:  0.7064999938011169 val_binary_acc 0.8881000280380249\n",
      "epoch :  742   cost :  1.0015309691429137   accuracy :  0.7356888651847839 val_acc:  0.7071999907493591 val_binary_acc 0.8891000151634216\n",
      "epoch :  743   cost :  1.0015836894512176   accuracy :  0.7362666726112366 val_acc:  0.7059000134468079 val_binary_acc 0.8880000114440918\n",
      "epoch :  744   cost :  1.001334536075592   accuracy :  0.7369666695594788 val_acc:  0.7057999968528748 val_binary_acc 0.8870999813079834\n",
      "epoch :  745   cost :  1.000869071483612   accuracy :  0.7367110848426819 val_acc:  0.7078999876976013 val_binary_acc 0.88919997215271\n",
      "epoch :  746   cost :  1.0008494079113008   accuracy :  0.7369666695594788 val_acc:  0.7070000171661377 val_binary_acc 0.888700008392334\n",
      "epoch :  747   cost :  1.0009197294712067   accuracy :  0.737333357334137 val_acc:  0.7081999778747559 val_binary_acc 0.8881000280380249\n",
      "epoch :  748   cost :  1.0009615063667296   accuracy :  0.7365999817848206 val_acc:  0.7074999809265137 val_binary_acc 0.8867999911308289\n",
      "epoch :  749   cost :  1.0012554824352264   accuracy :  0.7365777492523193 val_acc:  0.7064999938011169 val_binary_acc 0.8884000182151794\n",
      "epoch :  750   cost :  1.0009411990642547   accuracy :  0.7365333437919617 val_acc:  0.70660001039505 val_binary_acc 0.8881000280380249\n",
      "epoch :  751   cost :  1.0007710337638855   accuracy :  0.7366333603858948 val_acc:  0.7062000036239624 val_binary_acc 0.8888999819755554\n",
      "epoch :  752   cost :  1.00092014670372   accuracy :  0.7366889119148254 val_acc:  0.7064999938011169 val_binary_acc 0.8884000182151794\n",
      "epoch :  753   cost :  1.0010803163051605   accuracy :  0.736811101436615 val_acc:  0.7070000171661377 val_binary_acc 0.88919997215271\n",
      "epoch :  754   cost :  1.0011577665805818   accuracy :  0.7371777892112732 val_acc:  0.7074000239372253 val_binary_acc 0.8881999850273132\n",
      "epoch :  755   cost :  1.0006386041641235   accuracy :  0.7363888621330261 val_acc:  0.7069000005722046 val_binary_acc 0.8883000016212463\n",
      "epoch :  756   cost :  1.0007582128047943   accuracy :  0.736977756023407 val_acc:  0.7056000232696533 val_binary_acc 0.8881999850273132\n",
      "epoch :  757   cost :  1.000218254327774   accuracy :  0.7372000217437744 val_acc:  0.7071999907493591 val_binary_acc 0.888700008392334\n",
      "epoch :  758   cost :  1.0006351470947266   accuracy :  0.73698890209198 val_acc:  0.7059000134468079 val_binary_acc 0.8880000114440918\n",
      "epoch :  759   cost :  1.0005914628505708   accuracy :  0.7360777854919434 val_acc:  0.7057999968528748 val_binary_acc 0.8896999955177307\n",
      "epoch :  760   cost :  1.0011652052402495   accuracy :  0.7372778058052063 val_acc:  0.70660001039505 val_binary_acc 0.8870999813079834\n",
      "epoch :  761   cost :  1.0004620730876923   accuracy :  0.7376444339752197 val_acc:  0.7077000141143799 val_binary_acc 0.88919997215271\n",
      "epoch :  762   cost :  1.0004866659641267   accuracy :  0.7371333241462708 val_acc:  0.7074999809265137 val_binary_acc 0.8883000016212463\n",
      "epoch :  763   cost :  1.0002626001834871   accuracy :  0.7372666597366333 val_acc:  0.7063999772071838 val_binary_acc 0.8889999985694885\n",
      "epoch :  764   cost :  1.0003628075122832   accuracy :  0.7377444505691528 val_acc:  0.7074000239372253 val_binary_acc 0.8870000243186951\n",
      "epoch :  765   cost :  1.0002676248550415   accuracy :  0.7377444505691528 val_acc:  0.7064999938011169 val_binary_acc 0.8873000144958496\n",
      "epoch :  766   cost :  1.000041490793228   accuracy :  0.7376444339752197 val_acc:  0.7077000141143799 val_binary_acc 0.8895000219345093\n",
      "epoch :  767   cost :  1.0000842690467835   accuracy :  0.7372111082077026 val_acc:  0.7075999975204468 val_binary_acc 0.8880000114440918\n",
      "epoch :  768   cost :  1.0009977221488953   accuracy :  0.7374333143234253 val_acc:  0.7070000171661377 val_binary_acc 0.8878999948501587\n",
      "epoch :  769   cost :  1.0005613446235655   accuracy :  0.7370333075523376 val_acc:  0.70660001039505 val_binary_acc 0.8877999782562256\n",
      "epoch :  770   cost :  1.0003374874591828   accuracy :  0.7377222180366516 val_acc:  0.7063000202178955 val_binary_acc 0.8881999850273132\n",
      "epoch :  771   cost :  1.0004775762557983   accuracy :  0.7374777793884277 val_acc:  0.7045999765396118 val_binary_acc 0.8878999948501587\n",
      "epoch :  772   cost :  1.000234454870224   accuracy :  0.7371333241462708 val_acc:  0.7062000036239624 val_binary_acc 0.8880000114440918\n",
      "epoch :  773   cost :  1.000348037481308   accuracy :  0.7380444407463074 val_acc:  0.7080000042915344 val_binary_acc 0.8902000188827515\n",
      "epoch :  774   cost :  1.0002786278724671   accuracy :  0.7383111119270325 val_acc:  0.7080000042915344 val_binary_acc 0.8906000256538391\n",
      "epoch :  775   cost :  1.0003084659576416   accuracy :  0.7362889051437378 val_acc:  0.7063999772071838 val_binary_acc 0.8870000243186951\n",
      "epoch :  776   cost :  1.0009255588054657   accuracy :  0.7366666793823242 val_acc:  0.7060999870300293 val_binary_acc 0.8877999782562256\n",
      "epoch :  777   cost :  1.0001854598522186   accuracy :  0.7376999855041504 val_acc:  0.7080000042915344 val_binary_acc 0.8902000188827515\n",
      "epoch :  778   cost :  0.9996380388736725   accuracy :  0.7387222051620483 val_acc:  0.7077999711036682 val_binary_acc 0.88919997215271\n",
      "epoch :  779   cost :  0.9998137354850769   accuracy :  0.7379888892173767 val_acc:  0.7070000171661377 val_binary_acc 0.8877000212669373\n",
      "epoch :  780   cost :  0.9994645357131959   accuracy :  0.7386333346366882 val_acc:  0.7062000036239624 val_binary_acc 0.8881999850273132\n",
      "epoch :  781   cost :  0.999227452278137   accuracy :  0.7389666438102722 val_acc:  0.7084000110626221 val_binary_acc 0.8895000219345093\n",
      "epoch :  782   cost :  0.999078792333603   accuracy :  0.7390111088752747 val_acc:  0.7073000073432922 val_binary_acc 0.8891000151634216\n",
      "epoch :  783   cost :  0.9993287444114685   accuracy :  0.7383111119270325 val_acc:  0.707099974155426 val_binary_acc 0.8881000280380249\n",
      "epoch :  784   cost :  0.999369341135025   accuracy :  0.7385333180427551 val_acc:  0.7069000005722046 val_binary_acc 0.8870999813079834\n",
      "epoch :  785   cost :  0.9991470336914063   accuracy :  0.7390000224113464 val_acc:  0.7080000042915344 val_binary_acc 0.8885999917984009\n",
      "epoch :  786   cost :  0.9987498462200165   accuracy :  0.738777756690979 val_acc:  0.7085000276565552 val_binary_acc 0.8891000151634216\n",
      "epoch :  787   cost :  0.9992125391960145   accuracy :  0.7390666604042053 val_acc:  0.7078999876976013 val_binary_acc 0.8888999819755554\n",
      "epoch :  788   cost :  0.999253433942795   accuracy :  0.7385333180427551 val_acc:  0.7074000239372253 val_binary_acc 0.8899999856948853\n",
      "epoch :  789   cost :  0.999602872133255   accuracy :  0.738788902759552 val_acc:  0.7078999876976013 val_binary_acc 0.8898000121116638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  790   cost :  0.9996373891830443   accuracy :  0.7387111186981201 val_acc:  0.7074999809265137 val_binary_acc 0.8881999850273132\n",
      "epoch :  791   cost :  0.9994790077209473   accuracy :  0.7383221983909607 val_acc:  0.7077000141143799 val_binary_acc 0.8884000182151794\n",
      "epoch :  792   cost :  0.999226176738739   accuracy :  0.7383111119270325 val_acc:  0.7077000141143799 val_binary_acc 0.8881999850273132\n",
      "epoch :  793   cost :  0.9990851938724519   accuracy :  0.7390000224113464 val_acc:  0.7074000239372253 val_binary_acc 0.888700008392334\n",
      "epoch :  794   cost :  0.9990721166133879   accuracy :  0.7393110990524292 val_acc:  0.7080000042915344 val_binary_acc 0.8881000280380249\n",
      "epoch :  795   cost :  0.9985874593257904   accuracy :  0.739799976348877 val_acc:  0.7110999822616577 val_binary_acc 0.8903999924659729\n",
      "epoch :  796   cost :  0.9983967602252959   accuracy :  0.7396000027656555 val_acc:  0.7067999839782715 val_binary_acc 0.8877999782562256\n",
      "epoch :  797   cost :  0.9982431650161743   accuracy :  0.7391889095306396 val_acc:  0.7057999968528748 val_binary_acc 0.8876000046730042\n",
      "epoch :  798   cost :  0.9986047089099884   accuracy :  0.7387222051620483 val_acc:  0.7081000208854675 val_binary_acc 0.8895000219345093\n",
      "epoch :  799   cost :  0.9994994223117829   accuracy :  0.7383999824523926 val_acc:  0.7055000066757202 val_binary_acc 0.8871999979019165\n",
      "epoch :  800   cost :  0.9991450488567352   accuracy :  0.7393888831138611 val_acc:  0.7075999975204468 val_binary_acc 0.8891000151634216\n",
      "epoch :  801   cost :  0.9986016690731048   accuracy :  0.738777756690979 val_acc:  0.7055000066757202 val_binary_acc 0.8870000243186951\n",
      "epoch :  802   cost :  0.9990203559398652   accuracy :  0.7393666505813599 val_acc:  0.7080000042915344 val_binary_acc 0.88919997215271\n",
      "epoch :  803   cost :  0.9988115489482879   accuracy :  0.7386444211006165 val_acc:  0.7056000232696533 val_binary_acc 0.8889999985694885\n",
      "epoch :  804   cost :  0.9987527132034301   accuracy :  0.7397666573524475 val_acc:  0.7087000012397766 val_binary_acc 0.8894000053405762\n",
      "epoch :  805   cost :  0.9988165616989135   accuracy :  0.7391889095306396 val_acc:  0.7067999839782715 val_binary_acc 0.8867999911308289\n",
      "epoch :  806   cost :  0.9987321496009828   accuracy :  0.7393666505813599 val_acc:  0.7075999975204468 val_binary_acc 0.8889999985694885\n",
      "epoch :  807   cost :  0.998608511686325   accuracy :  0.7385444641113281 val_acc:  0.7056999802589417 val_binary_acc 0.8902000188827515\n",
      "epoch :  808   cost :  0.9987014472484588   accuracy :  0.7386888861656189 val_acc:  0.708299994468689 val_binary_acc 0.88919997215271\n",
      "epoch :  809   cost :  0.9986183941364288   accuracy :  0.7390444278717041 val_acc:  0.7064999938011169 val_binary_acc 0.8884000182151794\n",
      "epoch :  810   cost :  0.9985633254051208   accuracy :  0.7394777536392212 val_acc:  0.7075999975204468 val_binary_acc 0.8891000151634216\n",
      "epoch :  811   cost :  0.9979062974452972   accuracy :  0.7401000261306763 val_acc:  0.7081000208854675 val_binary_acc 0.8891000151634216\n",
      "epoch :  812   cost :  0.9977179050445557   accuracy :  0.7406444549560547 val_acc:  0.7084000110626221 val_binary_acc 0.8888000249862671\n",
      "epoch :  813   cost :  0.9976625919342041   accuracy :  0.7403666377067566 val_acc:  0.7087000012397766 val_binary_acc 0.8894000053405762\n",
      "epoch :  814   cost :  0.9976426124572754   accuracy :  0.7399222254753113 val_acc:  0.7070000171661377 val_binary_acc 0.8892999887466431\n",
      "epoch :  815   cost :  0.998048448562622   accuracy :  0.7398555278778076 val_acc:  0.7075999975204468 val_binary_acc 0.8895000219345093\n",
      "epoch :  816   cost :  0.9985328912734983   accuracy :  0.7386333346366882 val_acc:  0.7071999907493591 val_binary_acc 0.8891000151634216\n",
      "epoch :  817   cost :  0.9990488469600677   accuracy :  0.7394000291824341 val_acc:  0.7073000073432922 val_binary_acc 0.8878999948501587\n",
      "epoch :  818   cost :  0.9984984636306763   accuracy :  0.7396666407585144 val_acc:  0.708899974822998 val_binary_acc 0.8889999985694885\n",
      "epoch :  819   cost :  0.9981324672698976   accuracy :  0.7398444414138794 val_acc:  0.7084000110626221 val_binary_acc 0.8889999985694885\n",
      "epoch :  820   cost :  0.9977349996566773   accuracy :  0.7403333187103271 val_acc:  0.7074000239372253 val_binary_acc 0.8881000280380249\n",
      "epoch :  821   cost :  0.9976228892803192   accuracy :  0.740422248840332 val_acc:  0.7074999809265137 val_binary_acc 0.8885999917984009\n",
      "epoch :  822   cost :  0.9974350810050964   accuracy :  0.7404444217681885 val_acc:  0.7081000208854675 val_binary_acc 0.8898000121116638\n",
      "epoch :  823   cost :  0.997657400369644   accuracy :  0.7394444346427917 val_acc:  0.7074000239372253 val_binary_acc 0.888700008392334\n",
      "epoch :  824   cost :  0.9982743382453918   accuracy :  0.7395889163017273 val_acc:  0.70660001039505 val_binary_acc 0.8877999782562256\n",
      "epoch :  825   cost :  0.9979162931442261   accuracy :  0.7398777604103088 val_acc:  0.7069000005722046 val_binary_acc 0.8891000151634216\n",
      "epoch :  826   cost :  0.9981146574020386   accuracy :  0.7396222352981567 val_acc:  0.7075999975204468 val_binary_acc 0.8884999752044678\n",
      "epoch :  827   cost :  0.9981128156185151   accuracy :  0.7396110892295837 val_acc:  0.7075999975204468 val_binary_acc 0.8873999714851379\n",
      "epoch :  828   cost :  0.9984577238559723   accuracy :  0.7396110892295837 val_acc:  0.7077000141143799 val_binary_acc 0.8892999887466431\n",
      "epoch :  829   cost :  0.9977758884429933   accuracy :  0.7403444647789001 val_acc:  0.7095000147819519 val_binary_acc 0.890500009059906\n",
      "epoch :  830   cost :  0.9980896115303038   accuracy :  0.7391444444656372 val_acc:  0.7067000269889832 val_binary_acc 0.8888999819755554\n",
      "epoch :  831   cost :  0.9986353278160096   accuracy :  0.7397000193595886 val_acc:  0.7080000042915344 val_binary_acc 0.8891000151634216\n",
      "epoch :  832   cost :  0.9990691304206849   accuracy :  0.7389333248138428 val_acc:  0.7077999711036682 val_binary_acc 0.8892999887466431\n",
      "epoch :  833   cost :  0.9989591419696809   accuracy :  0.7389000058174133 val_acc:  0.7085999846458435 val_binary_acc 0.8888000249862671\n",
      "epoch :  834   cost :  0.9979315519332886   accuracy :  0.7402999997138977 val_acc:  0.7067000269889832 val_binary_acc 0.8884000182151794\n",
      "epoch :  835   cost :  0.9975304245948792   accuracy :  0.740411102771759 val_acc:  0.7074999809265137 val_binary_acc 0.8880000114440918\n",
      "epoch :  836   cost :  0.9976168036460876   accuracy :  0.739466667175293 val_acc:  0.707099974155426 val_binary_acc 0.8881000280380249\n",
      "epoch :  837   cost :  0.9975475728511811   accuracy :  0.7394111156463623 val_acc:  0.7077000141143799 val_binary_acc 0.8883000016212463\n",
      "epoch :  838   cost :  0.9983876466751099   accuracy :  0.7400000095367432 val_acc:  0.7064999938011169 val_binary_acc 0.8876000046730042\n",
      "epoch :  839   cost :  0.9975890219211578   accuracy :  0.7399222254753113 val_acc:  0.7056999802589417 val_binary_acc 0.8884000182151794\n",
      "epoch :  840   cost :  0.9976677119731904   accuracy :  0.7407666444778442 val_acc:  0.7093999981880188 val_binary_acc 0.8910999894142151\n",
      "epoch :  841   cost :  0.9973029673099516   accuracy :  0.7403666377067566 val_acc:  0.7085999846458435 val_binary_acc 0.8895000219345093\n",
      "epoch :  842   cost :  0.9975961923599244   accuracy :  0.7397888898849487 val_acc:  0.7060999870300293 val_binary_acc 0.8878999948501587\n",
      "epoch :  843   cost :  0.9980169296264647   accuracy :  0.7397444248199463 val_acc:  0.7055000066757202 val_binary_acc 0.8877000212669373\n",
      "epoch :  844   cost :  0.9977756917476653   accuracy :  0.7404999732971191 val_acc:  0.70660001039505 val_binary_acc 0.8888000249862671\n",
      "epoch :  845   cost :  0.9980578303337098   accuracy :  0.7401000261306763 val_acc:  0.7084000110626221 val_binary_acc 0.8889999985694885\n",
      "epoch :  846   cost :  0.9978120207786559   accuracy :  0.7397888898849487 val_acc:  0.7077999711036682 val_binary_acc 0.8894000053405762\n",
      "epoch :  847   cost :  0.997767686843872   accuracy :  0.7403666377067566 val_acc:  0.7056999802589417 val_binary_acc 0.8878999948501587\n",
      "epoch :  848   cost :  0.9974545836448669   accuracy :  0.7401221990585327 val_acc:  0.7077999711036682 val_binary_acc 0.8894000053405762\n",
      "epoch :  849   cost :  0.9974785208702086   accuracy :  0.7407888770103455 val_acc:  0.7077000141143799 val_binary_acc 0.8906000256538391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  850   cost :  0.9968958854675293   accuracy :  0.740933358669281 val_acc:  0.7070000171661377 val_binary_acc 0.8883000016212463\n",
      "epoch :  851   cost :  0.9971751809120178   accuracy :  0.7408221960067749 val_acc:  0.7070000171661377 val_binary_acc 0.8873000144958496\n",
      "epoch :  852   cost :  0.9968115508556366   accuracy :  0.7404555678367615 val_acc:  0.7064999938011169 val_binary_acc 0.8870999813079834\n",
      "epoch :  853   cost :  0.9968624889850617   accuracy :  0.7404999732971191 val_acc:  0.7077999711036682 val_binary_acc 0.8894000053405762\n",
      "epoch :  854   cost :  0.9971318900585175   accuracy :  0.7412222027778625 val_acc:  0.7056999802589417 val_binary_acc 0.8860999941825867\n",
      "epoch :  855   cost :  0.9969700336456299   accuracy :  0.7408444285392761 val_acc:  0.7067999839782715 val_binary_acc 0.8895999789237976\n",
      "epoch :  856   cost :  0.9973878920078278   accuracy :  0.7403888702392578 val_acc:  0.70660001039505 val_binary_acc 0.8881999850273132\n",
      "epoch :  857   cost :  0.9975143730640412   accuracy :  0.740244448184967 val_acc:  0.7085000276565552 val_binary_acc 0.8901000022888184\n",
      "epoch :  858   cost :  0.9969252824783325   accuracy :  0.7409777641296387 val_acc:  0.7073000073432922 val_binary_acc 0.8892999887466431\n",
      "epoch :  859   cost :  0.9968299269676207   accuracy :  0.7408111095428467 val_acc:  0.707099974155426 val_binary_acc 0.8881000280380249\n",
      "epoch :  860   cost :  0.996795928478241   accuracy :  0.7414666414260864 val_acc:  0.7099000215530396 val_binary_acc 0.8899000287055969\n",
      "epoch :  861   cost :  0.9966144025325774   accuracy :  0.7415333390235901 val_acc:  0.7085000276565552 val_binary_acc 0.8896999955177307\n",
      "epoch :  862   cost :  0.9970880866050722   accuracy :  0.7404666543006897 val_acc:  0.7059000134468079 val_binary_acc 0.887499988079071\n",
      "epoch :  863   cost :  0.9973236978054046   accuracy :  0.7396666407585144 val_acc:  0.7063000202178955 val_binary_acc 0.8888999819755554\n",
      "epoch :  864   cost :  0.9977954924106598   accuracy :  0.7408111095428467 val_acc:  0.7069000005722046 val_binary_acc 0.8881999850273132\n",
      "epoch :  865   cost :  0.9972192108631135   accuracy :  0.741266667842865 val_acc:  0.7081999778747559 val_binary_acc 0.8892999887466431\n",
      "epoch :  866   cost :  0.9969284653663635   accuracy :  0.7418777942657471 val_acc:  0.7069000005722046 val_binary_acc 0.8877999782562256\n",
      "epoch :  867   cost :  0.9965913712978364   accuracy :  0.7411555647850037 val_acc:  0.7075999975204468 val_binary_acc 0.8895000219345093\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-af5c85731f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#test batch만큼씩 넣어 각 값을 구함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mbatch2_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0macc_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mbatch2_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0macc_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mb_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch2_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch2_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#전체 data의 confusion matrix 값을 넣을 zero matrix를 생성\n",
    "cm=np.zeros(shape=(2,2),dtype=np.int32)\n",
    "\n",
    "#gpu 사용\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0 # 현재 epoch의 cost를 저장할 변수\n",
    "        acc=0     #현재 accuracy를 저장할 변수\n",
    "        sens=0    #현재 sensitivity를 저장할 변수\n",
    "        spec=0    #현재 specificity를 저장할 변수\n",
    "        prec=0    #현재 precision를 저장할 변수\n",
    "        curr=0    #현재 batch의 range를 나타낼 변수\n",
    "        curr1=0   #현재 test batch의 range를 나타낼 변수\n",
    "        curr2=0   #현재 val batch의 range를 나타낼 변수\n",
    "        val_acc=0 #validation accuracy를 저장할 변수\n",
    "        val_binary_acc=0\n",
    "        #batch normalization\n",
    "        batch_iter = int(total_batch / batch_size)\n",
    "        orders=np.arange(0,batch_size*batch_iter)\n",
    "        #매 epoch마다 배치의 순서 자체도 shuffle\n",
    "        np.random.shuffle(orders)\n",
    "        \n",
    "        #batch 만큼만 데이터를 넣어 학습\n",
    "        for i in range(batch_iter):\n",
    "            #batch 지정\n",
    "            batch_xs = input_array[orders[range(curr1,curr1+batch_size)]]\n",
    "            batch_ys = target[orders[range(curr1,curr1+batch_size)]]\n",
    "            #어떤 data를 feed할지 지정\n",
    "            feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "            #loss계산, 학습\n",
    "            c, _ = sess.run([loss, train], feed_dict=feed_dict)\n",
    "            \n",
    "            #다음 batch\n",
    "            curr1 += batch_size\n",
    "            \n",
    "            #cost 저장\n",
    "            avg_cost += c / batch_iter\n",
    "        #test batch만큼씩 넣어 각 값을 구함\n",
    "        for j in range(1):\n",
    "            batch2_xs = input_array[range(curr,curr+acc_batch_size)]\n",
    "            batch2_ys = target[range(curr,curr+acc_batch_size)]\n",
    "            b_acc = sess.run([accuracy], feed_dict={X:batch2_xs,Y: batch2_ys})\n",
    "            #다음 batch\n",
    "            curr += acc_batch_size\n",
    "            \n",
    "            #현재 accuracy를 저장\n",
    "            acc += b_acc[0]\n",
    "        for k in range(1):\n",
    "            batch2_xs = val_input[range(curr2,curr2+val_batch_size)]\n",
    "            batch2_ys = val_lab[range(curr2,curr2+val_batch_size)]\n",
    "            v_acc,v_b_acc = sess.run([accuracy,binary_acc], feed_dict={X:batch2_xs,Y: batch2_ys})\n",
    "            #다음 batch\n",
    "            curr2 += val_batch_size\n",
    "            #현재 accuracy를 저장\n",
    "            val_acc += v_acc\n",
    "            val_binary_acc+=v_b_acc\n",
    "        \n",
    "        total_acc.append(acc)\n",
    "        total_val_acc.append(val_acc)\n",
    "        total_val_b_acc.append(val_binary_acc)\n",
    "            \n",
    "        #매 epoch마다 지표 출력\n",
    "        print(\"epoch : \", epoch,\"  cost : \", avg_cost, \"  accuracy : \", acc,\"val_acc: \", val_acc,\"val_binary_acc\", val_binary_acc\n",
    "              )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6717"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(accuracy,feed_dict={X:val_input,Y:val_lab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8777"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reduce_mean(tf.cast((tf.equal((tf.argmax(Y_one_hot, 1)>0),(prediction>0))), tf.float32)),feed_dict={X:val_input,Y:val_lab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(Y_one_hot,feed_dict={Y:val_lab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0],\n",
       "       [3],\n",
       "       ...,\n",
       "       [1],\n",
       "       [3],\n",
       "       [0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run( (prediction>0),feed_dict={X:val_input,Y:val_lab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [3600000] != values[1].shape = [400000]\n\t [[Node: confusion_matrix/stack_1 = Pack[N=2, T=DT_INT64, axis=1, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](confusion_matrix/control_dependency, confusion_matrix/control_dependency_1)]]\n\t [[Node: confusion_matrix/stack/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_303_confusion_matrix/stack\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'confusion_matrix/stack_1', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-8d7d771ffe42>\", line 33, in <module>\n    confusion_matrix=tf.confusion_matrix(tf.reshape(softmaxed,[-1]), tf.reshape(Y_one_hot,[-1]))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/confusion_matrix.py\", line 189, in confusion_matrix\n    indices = array_ops.stack([labels, predictions], axis=1)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 945, in stack\n    return gen_array_ops.pack(values, axis=axis, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4191, in pack\n    \"Pack\", values=values, axis=axis, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Shapes of all inputs must match: values[0].shape = [3600000] != values[1].shape = [400000]\n\t [[Node: confusion_matrix/stack_1 = Pack[N=2, T=DT_INT64, axis=1, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](confusion_matrix/control_dependency, confusion_matrix/control_dependency_1)]]\n\t [[Node: confusion_matrix/stack/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_303_confusion_matrix/stack\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [3600000] != values[1].shape = [400000]\n\t [[Node: confusion_matrix/stack_1 = Pack[N=2, T=DT_INT64, axis=1, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](confusion_matrix/control_dependency, confusion_matrix/control_dependency_1)]]\n\t [[Node: confusion_matrix/stack/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_303_confusion_matrix/stack\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c3ccfe3fb6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mbatch2_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0macc_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mbatch2_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0macc_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mb_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch2_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch2_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;31m#다음 batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mcurr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [3600000] != values[1].shape = [400000]\n\t [[Node: confusion_matrix/stack_1 = Pack[N=2, T=DT_INT64, axis=1, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](confusion_matrix/control_dependency, confusion_matrix/control_dependency_1)]]\n\t [[Node: confusion_matrix/stack/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_303_confusion_matrix/stack\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'confusion_matrix/stack_1', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-8d7d771ffe42>\", line 33, in <module>\n    confusion_matrix=tf.confusion_matrix(tf.reshape(softmaxed,[-1]), tf.reshape(Y_one_hot,[-1]))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/confusion_matrix.py\", line 189, in confusion_matrix\n    indices = array_ops.stack([labels, predictions], axis=1)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 945, in stack\n    return gen_array_ops.pack(values, axis=axis, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4191, in pack\n    \"Pack\", values=values, axis=axis, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Shapes of all inputs must match: values[0].shape = [3600000] != values[1].shape = [400000]\n\t [[Node: confusion_matrix/stack_1 = Pack[N=2, T=DT_INT64, axis=1, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](confusion_matrix/control_dependency, confusion_matrix/control_dependency_1)]]\n\t [[Node: confusion_matrix/stack/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_303_confusion_matrix/stack\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "#epoch별 accuracy, specificity, sensitivity, precision, validation accuracy을 저장할 list를 만듦\n",
    "total_acc=[]\n",
    "total_sp=[]\n",
    "total_se=[]\n",
    "total_pr=[]\n",
    "total_val_acc=[]\n",
    "\n",
    "#전체 data의 confusion matrix 값을 넣을 zero matrix를 생성\n",
    "cm=np.zeros(shape=(2,2),dtype=np.int32)\n",
    "\n",
    "#gpu 사용\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    for epoch in range(epoch):\n",
    "        avg_cost = 0 # 현재 epoch의 cost를 저장할 변수\n",
    "        acc=0     #현재 accuracy를 저장할 변수\n",
    "        sens=0    #현재 sensitivity를 저장할 변수\n",
    "        spec=0    #현재 specificity를 저장할 변수\n",
    "        prec=0    #현재 precision를 저장할 변수\n",
    "        curr=0    #현재 batch의 range를 나타낼 변수\n",
    "        curr1=0   #현재 test batch의 range를 나타낼 변수\n",
    "        curr2=0   #현재 val batch의 range를 나타낼 변수\n",
    "        val_acc=0 #validation accuracy를 저장할 변수\n",
    "        #batch normalization\n",
    "        batch_iter = int(total_batch / batch_size)\n",
    "        orders=np.arange(0,batch_size*batch_iter)\n",
    "        #매 epoch마다 배치의 순서 자체도 shuffle\n",
    "        np.random.shuffle(orders)\n",
    "        \n",
    "        #batch 만큼만 데이터를 넣어 학습\n",
    "        for i in range(batch_iter):\n",
    "            #batch 지정\n",
    "            batch_xs = input_array[orders[range(curr,curr+batch_size)]]\n",
    "            batch_ys = target[orders[range(curr,curr+batch_size)]]\n",
    "            #어떤 data를 feed할지 지정\n",
    "            feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "            #loss계산, 학습\n",
    "            c, _ = sess.run([loss, train], feed_dict=feed_dict)\n",
    "            \n",
    "            #다음 batch\n",
    "            curr1 += batch_size\n",
    "            \n",
    "            #cost 저장\n",
    "            avg_cost += c / batch_iter\n",
    "        #test batch만큼씩 넣어 각 값을 구함\n",
    "        for j in range(1):\n",
    "            batch2_xs = input_array[range(curr,curr+acc_batch_size)]\n",
    "            batch2_ys = target[range(curr,curr+acc_batch_size)]\n",
    "            b_acc,cf = sess.run([accuracy,confusion_matrix], feed_dict={X:batch2_xs,Y: batch2_ys})\n",
    "            #다음 batch\n",
    "            curr += acc_batch_size\n",
    "            \n",
    "            #현재 accuracy를 저장\n",
    "            acc += b_acc/10    \n",
    "            #현재 batch에서의 confusionmatrix의 값을 저장\n",
    "            cm += cf\n",
    "        \n",
    "        #val batch만큼씩 넣어 각 값을 구함\n",
    "        for j in range(3):\n",
    "            batch3_xs = val_d[range(curr2,curr2+val_batch_size)]\n",
    "            batch3_ys = val_l[range(curr2,curr2+val_batch_size)]\n",
    "            v_acc = sess.run([accuracy], feed_dict={X:batch3_xs,Y: batch3_ys})\n",
    "            #다음 batch\n",
    "            curr2 += val_batch_size\n",
    "            \n",
    "            #현재 accuracy를 저장\n",
    "            val_acc += v_acc[0]/3\n",
    "        \n",
    "        #label값이 0,1이므로 보통 confusion matrix의 값과는 다른 형태가 나옴, 각 지표을 계산\n",
    "        sens +=cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "        spec +=cm[0,0]/(cm[0,0]+cm[1,0])\n",
    "        prec +=cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "        \n",
    "        #현재 epoch의 지표를 저장\n",
    "        total_acc.append(acc)\n",
    "        total_sp.append(spec)\n",
    "        total_se.append(sens)\n",
    "        total_pr.append(prec)\n",
    "        total_val_acc.append(val_acc)\n",
    "        #매 epoch마다 지표 출력\n",
    "        print(\"epoch : \", epoch,\"  cost : \", avg_cost, \"  accuracy : \", acc,\n",
    "              \"\\nspecificity : \",spec, \"  sensitivity : \", sens, \"  precision : \", prec,\n",
    "              \"\\nvalidation accuracy : \")\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            saver.save(sess, \"my_test_model/2lstm_1fc_real_data\", global_step=epoch+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ggplot처럼 plot  하나씩 추가하는 겁니다.\n",
    "plt.plot(total_acc,label = 'accuracy')\n",
    "plt.plot(total_val_acc,label = 'val_acc')\n",
    "plt.plot(total_val_b_acc,label = 'val_b_acc')\n",
    "plt.legend()\n",
    "#이렇게 두개하면 두개가 그려짐\n",
    "\n",
    "#데이터를 하나만 넣으면 index(x축에따라) 데이터가 어떻게 달라지는지를 출력해주어서\n",
    "#y의 범위를 지정해줘야 됩니다.\n",
    "#범위 지정안하면 min max가 lim 이됨\n",
    "plt.ylim(0,1)\n",
    "\n",
    "#플랏을 띄워주라는 명령어\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose_1:0' shape=(?, 88, 300) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.core.shape_base.stack(arrays, axis=0, out=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 88, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa= input_array[0:3]\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa=np.stack((aa[0,1,:],aa[0,2,:]),axis=0)\n",
    "np.stack((aaa[0],aa[0,1,:],aa[0,2,:]),axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shaping(inputs,l_word,batch_size):\n",
    "    for k in range(batch_size):\n",
    "        if k is 0:\n",
    "            new_arr = (inputs[k,l_word])\n",
    "        else :\n",
    "            new_arr = new_arr+(inputs[k,l_word])\n",
    "    return np.stack(new_arr)\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
