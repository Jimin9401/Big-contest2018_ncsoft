{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier # rf분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(y_pred, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    \n",
    "    pre = precision_score(y_true = labels, y_pred = y_pred, average=None)\n",
    "    rec = recall_score(y_true = labels, y_pred = y_pred, average=None)\n",
    "    f1_score = 8/(sum(1/pre) + sum(1/rec))\n",
    "\n",
    "    return 'f1', f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(X_val, y_val, model,mapping):\n",
    "    \"\"\"\n",
    "    Model evaluation function for multiclass classification problem\n",
    "    1) F-1 score, Precision, Recall\n",
    "    2) ROC curve, PR curve는 추후에 생각\n",
    "    \"\"\"\n",
    " \n",
    "    #### predict the value\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    #print('-'*50)\n",
    "    #print('2. F1-score')\n",
    "    \n",
    "    # inverse pre/ rec\n",
    "    pre = precision_score(y_true = y_val, y_pred = y_pred, average=None)\n",
    "    rec = recall_score(y_true = y_val, y_pred = y_pred, average=None)\n",
    "\n",
    "    # f1 measure\n",
    "    f1_score = 8/(sum(1/pre) + sum(1/rec))\n",
    "    \n",
    "    # view - precision recall\n",
    "    table = pd.DataFrame([])\n",
    "\n",
    "    for i,k in enumerate(mapping.keys()):\n",
    "        table[k] = [pre[i],rec[i]]\n",
    "    table.index = ['precision','recall']\n",
    "    # print(table)\n",
    "    \n",
    "    # view - f1\n",
    "    #print('F1_score %.3f'%f1_score)\n",
    "    #print('='*50)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_487.csv')\n",
    "X_test = pd.read_csv('X_test_487.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load class\n",
    "train_label = pd.read_csv('temp_data/train_label_lite.csv')\n",
    "hasher = pd.read_csv('temp_data/test_id.csv')\n",
    "label_map = {'retained':0,'2month':1,'month':2,'week':3}\n",
    "inv_map = {label_map[k]:k for k in label_map.keys()}\n",
    "y_train = pd.Series([label_map[l] for l in train_label.label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 487)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RF 모델\n",
    "model = RandomForestClassifier(criterion='entropy',n_estimators=300,random_state= 7, n_jobs=-1)\n",
    "X_train_rf = X_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.: [22500 22500 22500 22500], F1: 0.715\n",
      "Fold: 2, Class dist.: [22500 22500 22500 22500], F1: 0.717\n",
      "Fold: 3, Class dist.: [22500 22500 22500 22500], F1: 0.724\n",
      "Fold: 4, Class dist.: [22500 22500 22500 22500], F1: 0.726\n",
      "Fold: 5, Class dist.: [22500 22500 22500 22500], F1: 0.716\n",
      "Fold: 6, Class dist.: [22500 22500 22500 22500], F1: 0.717\n",
      "Fold: 7, Class dist.: [22500 22500 22500 22500], F1: 0.716\n",
      "Fold: 8, Class dist.: [22500 22500 22500 22500], F1: 0.713\n",
      "Fold: 9, Class dist.: [22500 22500 22500 22500], F1: 0.705\n",
      "Fold: 10, Class dist.: [22500 22500 22500 22500], F1: 0.710\n",
      "\n",
      "CV F1: 0.716 +/- 0.006\n"
     ]
    }
   ],
   "source": [
    "#### cross validation\n",
    "kfold = StratifiedKFold(n_splits = 10 ,random_state = 7).split(X_train_rf, y_train)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    model.fit(X_train_rf.iloc[train,:], y_train[train])\n",
    "    score = f1(X_train_rf.iloc[test,:], y_train[test], model,label_map)\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, F1: %.3f' % (k+1,np.bincount(y_train[train]), score))\n",
    "    \n",
    "print('\\nCV F1: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### feature selection by RF\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],axis=0)\n",
    "indices = np.argsort(importances) # ascending\n",
    "\n",
    "#### feature ranking\n",
    "feature_ranking = [(indices[f],importances[indices[f]]) for f in range(X_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### state of art feature.... 300개 정도... importance ratio 조정!!!\n",
    "NUM_OF_FEATURES = len([(i,f) for i, f in feature_ranking if f > 0.0005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OF_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.DataFrame({'importance': model.feature_importances_, 'feature': X_train.columns}).sort_values(by=['importance'], ascending=[False])[:NUM_OF_FEATURES]['feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 352)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FEATURE SELECTION\n",
    "X_train = X_train[col]\n",
    "# X_test = X_test[col]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### xgb\n",
    "grid_result = []\n",
    "param = {}\n",
    "#### XGB parameters\n",
    "## General Parameters\n",
    "param['n_gpus'] = -1\n",
    "param['tree_method'] = 'gpu_hist'\n",
    "param['silent'] = 0\n",
    "\n",
    "## Booster Parameters\n",
    "param['n_estimators'] = 3000 #요기...\n",
    "param['learning_rate'] = 0.01\n",
    "param['min_child_weight'] = 2\n",
    "param['max_depth'] = 10\n",
    "param['gamma'] = 0\n",
    "param['reg_alpha'] = 0.1\n",
    "param['reg_lambda'] = 0.03\n",
    "param['subsample'] = 0.9\n",
    "param['colsample_bytree'] = 0.75\n",
    "param['scale_pos_weight'] = 1\n",
    "\n",
    "## Learning task parameters\n",
    "param['num_class'] = 4\n",
    "param['objective'] = 'multi:softmax'\n",
    "param['seed'] = 7\n",
    "\n",
    "model = xgb.XGBClassifier(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 160\n"
     ]
    }
   ],
   "source": [
    " #### step 1 : tuning n_estimators with cross validation\n",
    "print(\"===============================================\")\n",
    "print(\"Find the n_estimators\")\n",
    "xgtrain = xgb.DMatrix(X_train.values, label= y_train.values.reshape(-1,1))\n",
    "cvresult = xgb.cv(param, xgtrain, num_boost_round = param['n_estimators'], nfold = 5, metrics = \"mlogloss\", early_stopping_rounds = 100)\n",
    "print(\"Optimal n_estimators : %d\"%cvresult.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.: [20000 20000 20000 20000], F1: 0.743\n",
      "Fold: 2, Class dist.: [20000 20000 20000 20000], F1: 0.741\n",
      "Fold: 3, Class dist.: [20000 20000 20000 20000], F1: 0.747\n",
      "Fold: 4, Class dist.: [20000 20000 20000 20000], F1: 0.747\n",
      "Fold: 5, Class dist.: [20000 20000 20000 20000], F1: 0.737\n",
      "\n",
      "CV F1: 0.743 +/- 0.004\n"
     ]
    }
   ],
   "source": [
    "#### cross validation(for NA)\n",
    "kfold = StratifiedKFold(n_splits = 5 ,random_state = 7,shuffle=True).split(X_train, y_train)\n",
    "scores = []\n",
    "predict_set = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    model.fit(X_train.iloc[train,:], y_train[train], eval_metric = F1)\n",
    "    score = model.score(X_train.iloc[test,:], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, F1: %.3f' % (k+1,np.bincount(y_train[train]), score))\n",
    "    ### predict\n",
    "    y_pred = model.predict(X_train.iloc[test,:])\n",
    "    predict_set += [(x,inv_map[y_pred[i]]) for i,x in enumerate(test)]\n",
    "print('\\nCV F1: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.01,\n",
       "       max_delta_step=0, max_depth=10, min_child_weight=2, missing=None,\n",
       "       n_estimators=3000, n_gpus=-1, n_jobs=1, nthread=None, num_class=4,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0.1,\n",
       "       reg_lambda=0.03, scale_pos_weight=1, seed=7, silent=0,\n",
       "       subsample=0.9, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 기존 state of art 학습!!!\n",
    "model.fit(X_train,y_train,eval_metric = f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### result\n",
    "results = [inv_map[x] for x in my_pred]\n",
    "result = pd.DataFrame({'acc_id':['te' + str(x) for x in X_test.index], 'label': results})\n",
    "result['acc_id'] = [hasher.iloc[i,0] for i in range(len(result.acc_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('new_xgb_2018_09_04_4.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
