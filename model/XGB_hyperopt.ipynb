{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import module, function and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier # rf분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(y_pred, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    \n",
    "    pre = precision_score(y_true = labels, y_pred = y_pred, average=None)\n",
    "    rec = recall_score(y_true = labels, y_pred = y_pred, average=None)\n",
    "    f1_score = 8/(sum(1/pre) + sum(1/rec))\n",
    "\n",
    "    return 'f1', f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load class\n",
    "train_label = pd.read_csv('temp_data/train_label_lite.csv')\n",
    "# hasher = pd.read_csv('test_id.csv')\n",
    "label_map = {'retained':0,'2month':1,'month':2,'week':3}\n",
    "y_train = pd.Series([label_map[l] for l in train_label.label])\n",
    "inv_map = {label_map[k]:k for k in label_map.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'colsample_bytree': 0.9, 'gamma': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.097, 'reg_lambda': 0.069, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
    "===============================================\n",
    "Find the n_estimators\n",
    "Optimal n_estimators : 227\n",
    "5-fold of Xgboost F1: 0.72345 +/- 0.00165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### xgb\n",
    "grid_result = []\n",
    "param = {}\n",
    "#### XGB parameters\n",
    "## General Parameters\n",
    "param['n_gpus'] = -1\n",
    "param['tree_method'] = 'gpu_hist'\n",
    "param['silent'] = 0\n",
    "\n",
    "## Booster Parameters\n",
    "param['n_estimators'] = 224 #요기...\n",
    "param['learning_rate'] = 0.1\n",
    "param['min_child_weight'] = 10\n",
    "param['max_depth'] = 20\n",
    "param['gamma'] = 0.1\n",
    "param['reg_alpha'] =0.01\n",
    "param['reg_lambda'] = 0.05\n",
    "param['subsample'] = 0.85\n",
    "param['colsample_bytree'] = 0.72\n",
    "param['scale_pos_weight'] = 1\n",
    "\n",
    "## Learning task parameters\n",
    "param['num_class'] = 4\n",
    "param['objective'] = 'multi:softmax'\n",
    "param['seed'] = 7\n",
    "\n",
    "## update?\n",
    "#param['process_type'] = 'update'\n",
    "#param['updater'] = 'refresh'\n",
    "#param['refresh_leaf'] = True\n",
    "model = xgb.XGBClassifier(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### cross validation(for NA)\n",
    "kfold = StratifiedKFold(n_splits = 5 ,random_state = 7,shuffle=True).split(X_train, y_train)\n",
    "scores = []\n",
    "predict_set = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    model.fit(X_train.iloc[train,:], y_train[train],eval_metric = F1)  ####요부분 trimming\n",
    "    score = model.score(X_train.iloc[test,:], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, F1: %.3f' % (k+1,np.bincount(y_train[train]), score))\n",
    "    ### predict\n",
    "    y_pred = model.predict(X_train.iloc[test,:])\n",
    "    predict_set += [(x,inv_map[y_pred[i]]) for i,x in enumerate(test)]\n",
    "print('\\nCV F1: %.6f +/- %.6f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7417,,,,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperopt Xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_call_count = 0\n",
    "cur_best_score = 0\n",
    "cur_best_std = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_weight': hp.quniform('min_child_weight',1,4,0.05),\n",
    "    'max_depth':hp.choice('max_deph',range(7,18)),\n",
    "    \n",
    "    'gamma': hp.quniform('gamma',0.0001,1,0.05),\n",
    "    'reg_alpha': hp.quniform('reg_alpha',0.0001,0.1,0.001),\n",
    "    'reg_lambda': hp.quniform('reg_lambda',0.0001,0.1,0.001),\n",
    "    'subsample': hp.quniform('subsample',0.6,1,0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree',0.6,1,0.05),\n",
    "    \n",
    "    'num_class':4,\n",
    "    'objective': 'multi:softmax',\n",
    "    'seed': 7,\n",
    "    \n",
    "    'n_gpus' : -1,\n",
    "    'tree_method' : 'gpu_hist',\n",
    "    'silent' : 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_classifier(params): # hyperopt의 objective function은 params를 input으로 받는다.\n",
    "    \n",
    "    global obj_call_count, cur_best_score, cur_best_std, X_train, y_train # 우리가 input할 데이터는 global변수화!\n",
    "    \n",
    "    obj_call_count += 1\n",
    "    print('\\nXgboost objective call #{} cur_best_score={:7.5f} cur_best_std={:7.5f}'.format(obj_call_count,cur_best_score,cur_best_std) )\n",
    "    \n",
    "    #### sampling parameters from the hyperparameter params\n",
    "    xgb_params = sample(params)\n",
    "    \n",
    "    if xgb_params['max_depth'] >= 10:\n",
    "        xgb_params['min_child_weight'] = xgb_params['max_depth'] - 6\n",
    "        \n",
    "    \n",
    "    print(xgb_params)\n",
    "    \n",
    "     #### step 1 : tuning n_estimators with cross validation\n",
    "    print(\"===============================================\")\n",
    "    print(\"Find the n_estimators\")\n",
    "    xgtrain = xgb.DMatrix(X_train.values, label= y_train.values.reshape(-1,1))\n",
    "    cvresult = xgb.cv(xgb_params, xgtrain, num_boost_round = xgb_params['n_estimators'], nfold = 5, feval=F1, \n",
    "                      early_stopping_rounds = 50 ,stratified=True, shuffle=True)\n",
    "    print(\"Optimal n_estimators : %d\"%(cvresult.shape[0]))\n",
    "    \n",
    "    \n",
    "    f1_mean = cvresult['test-f1-mean'].max()\n",
    "    f1_std = cvresult['test-f1-std'].loc[cvresult['test-f1-mean']==f1_mean].values[0]\n",
    "    \n",
    "    print('5-fold of Xgboost F1: %.5f +/- %.5f' % (f1_mean,f1_std))\n",
    "    \n",
    "    if f1_mean > cur_best_score:\n",
    "        cur_best_score = f1_mean\n",
    "        cur_best_std = f1_std\n",
    "        \n",
    "    #### minimize metric\n",
    "    loss = 1 - f1_mean\n",
    "    loss_var = f1_std\n",
    "    \n",
    "    return {'loss': loss , 'loss_variance': loss_var ,'status':STATUS_OK ,'attachments':{'cvresult':cvresult}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xgboost objective call #1 cur_best_score=0.00000 cur_best_std=0.00000\n",
      "{'colsample_bytree': 0.6000000000000001, 'gamma': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 3.6500000000000004, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.029, 'reg_lambda': 0.027, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 615\n",
      "5-fold of Xgboost F1: 0.72199 +/- 0.00167\n",
      "\n",
      "Xgboost objective call #2 cur_best_score=0.72199 cur_best_std=0.00167\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.081, 'reg_lambda': 0.011, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 184\n",
      "5-fold of Xgboost F1: 0.72166 +/- 0.00331\n",
      "\n",
      "Xgboost objective call #3 cur_best_score=0.72199 cur_best_std=0.00167\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.55, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1.25, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.044, 'reg_lambda': 0.081, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 231\n",
      "5-fold of Xgboost F1: 0.72015 +/- 0.00425\n",
      "\n",
      "Xgboost objective call #4 cur_best_score=0.72199 cur_best_std=0.00167\n",
      "{'colsample_bytree': 0.6000000000000001, 'gamma': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 17, 'min_child_weight': 11, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.051000000000000004, 'reg_lambda': 0.044, 'seed': 7, 'silent': 0, 'subsample': 0.65, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 138\n",
      "5-fold of Xgboost F1: 0.72018 +/- 0.00259\n",
      "\n",
      "Xgboost objective call #5 cur_best_score=0.72199 cur_best_std=0.00167\n",
      "{'colsample_bytree': 0.8, 'gamma': 0.6000000000000001, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 9, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.006, 'reg_lambda': 0.053, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 201\n",
      "5-fold of Xgboost F1: 0.72298 +/- 0.00180\n",
      "\n",
      "Xgboost objective call #6 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.8500000000000001, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 2.95, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.021, 'reg_lambda': 0.008, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 611\n",
      "5-fold of Xgboost F1: 0.72058 +/- 0.00280\n",
      "\n",
      "Xgboost objective call #7 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.6000000000000001, 'gamma': 1.0, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 2.95, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.08, 'reg_lambda': 0.095, 'seed': 7, 'silent': 0, 'subsample': 0.8, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 400\n",
      "5-fold of Xgboost F1: 0.72163 +/- 0.00271\n",
      "\n",
      "Xgboost objective call #8 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.089, 'reg_lambda': 0.08600000000000001, 'seed': 7, 'silent': 0, 'subsample': 0.65, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 221\n",
      "5-fold of Xgboost F1: 0.71894 +/- 0.00301\n",
      "\n",
      "Xgboost objective call #9 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.061, 'reg_lambda': 0.011, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 292\n",
      "5-fold of Xgboost F1: 0.72247 +/- 0.00082\n",
      "\n",
      "Xgboost objective call #10 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.65, 'gamma': 0.8, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.042, 'reg_lambda': 0.041, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 224\n",
      "5-fold of Xgboost F1: 0.72165 +/- 0.00393\n",
      "\n",
      "Xgboost objective call #11 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.05, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1.25, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.076, 'reg_lambda': 0.012, 'seed': 7, 'silent': 0, 'subsample': 0.65, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 299\n",
      "5-fold of Xgboost F1: 0.72053 +/- 0.00203\n",
      "\n",
      "Xgboost objective call #12 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 9, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.077, 'reg_lambda': 0.073, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 255\n",
      "5-fold of Xgboost F1: 0.72270 +/- 0.00228\n",
      "\n",
      "Xgboost objective call #13 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.25, 'learning_rate': 0.1, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.021, 'reg_lambda': 0.041, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 249\n",
      "5-fold of Xgboost F1: 0.72278 +/- 0.00196\n",
      "\n",
      "Xgboost objective call #14 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.006, 'reg_lambda': 0.036000000000000004, 'seed': 7, 'silent': 0, 'subsample': 0.8, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 218\n",
      "5-fold of Xgboost F1: 0.72216 +/- 0.00202\n",
      "\n",
      "Xgboost objective call #15 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.9, 'learning_rate': 0.1, 'max_depth': 17, 'min_child_weight': 11, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.048, 'reg_lambda': 0.064, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 193\n",
      "5-fold of Xgboost F1: 0.72240 +/- 0.00182\n",
      "\n",
      "Xgboost objective call #16 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.0, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 2.4000000000000004, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.013000000000000001, 'reg_lambda': 0.057, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal n_estimators : 427\n",
      "5-fold of Xgboost F1: 0.72028 +/- 0.00248\n",
      "\n",
      "Xgboost objective call #17 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.8, 'gamma': 0.55, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.023, 'reg_lambda': 0.044, 'seed': 7, 'silent': 0, 'subsample': 0.8, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 179\n",
      "5-fold of Xgboost F1: 0.72173 +/- 0.00301\n",
      "\n",
      "Xgboost objective call #18 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.014, 'reg_lambda': 0.07200000000000001, 'seed': 7, 'silent': 0, 'subsample': 0.75, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 205\n",
      "5-fold of Xgboost F1: 0.72124 +/- 0.00226\n",
      "\n",
      "Xgboost objective call #19 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.30000000000000004, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 9, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.002, 'reg_lambda': 0.08600000000000001, 'seed': 7, 'silent': 0, 'subsample': 0.7000000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 138\n",
      "5-fold of Xgboost F1: 0.72133 +/- 0.00265\n",
      "\n",
      "Xgboost objective call #20 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 0.15000000000000002, 'learning_rate': 0.1, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.067, 'reg_lambda': 0.076, 'seed': 7, 'silent': 0, 'subsample': 0.7000000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 208\n",
      "5-fold of Xgboost F1: 0.72061 +/- 0.00224\n",
      "\n",
      "Xgboost objective call #21 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.7000000000000001, 'gamma': 0.65, 'learning_rate': 0.1, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.033, 'reg_lambda': 0.056, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 299\n",
      "5-fold of Xgboost F1: 0.72250 +/- 0.00241\n",
      "\n",
      "Xgboost objective call #22 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.7000000000000001, 'gamma': 0.45, 'learning_rate': 0.1, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.003, 'reg_lambda': 0.027, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 189\n",
      "5-fold of Xgboost F1: 0.72270 +/- 0.00200\n",
      "\n",
      "Xgboost objective call #23 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.8, 'gamma': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.012, 'reg_lambda': 0.028, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 260\n",
      "5-fold of Xgboost F1: 0.72247 +/- 0.00243\n",
      "\n",
      "Xgboost objective call #24 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.7000000000000001, 'gamma': 0.45, 'learning_rate': 0.1, 'max_depth': 16, 'min_child_weight': 10, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.035, 'reg_lambda': 0.053, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 151\n",
      "5-fold of Xgboost F1: 0.72259 +/- 0.00196\n",
      "\n",
      "Xgboost objective call #25 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.65, 'gamma': 0.4, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 9, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.022, 'reg_lambda': 0.064, 'seed': 7, 'silent': 0, 'subsample': 0.75, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 145\n",
      "5-fold of Xgboost F1: 0.72192 +/- 0.00254\n",
      "\n",
      "Xgboost objective call #26 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.8, 'gamma': 0.65, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 9, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.099, 'reg_lambda': 0.035, 'seed': 7, 'silent': 0, 'subsample': 0.75, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 159\n",
      "5-fold of Xgboost F1: 0.72201 +/- 0.00344\n",
      "\n",
      "Xgboost objective call #27 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.35000000000000003, 'learning_rate': 0.1, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.001, 'reg_lambda': 0.022, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 245\n",
      "5-fold of Xgboost F1: 0.72241 +/- 0.00287\n",
      "\n",
      "Xgboost objective call #28 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.65, 'gamma': 0.75, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 1.75, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.01, 'reg_lambda': 0.001, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 660\n",
      "5-fold of Xgboost F1: 0.71913 +/- 0.00259\n",
      "\n",
      "Xgboost objective call #29 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.7000000000000001, 'gamma': 0.55, 'learning_rate': 0.1, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.024, 'reg_lambda': 0.063, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 209\n",
      "5-fold of Xgboost F1: 0.72288 +/- 0.00291\n",
      "\n",
      "Xgboost objective call #30 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.7000000000000001, 'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 3.4000000000000004, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.029, 'reg_lambda': 0.098, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 619\n",
      "5-fold of Xgboost F1: 0.72152 +/- 0.00199\n",
      "\n",
      "Xgboost objective call #31 cur_best_score=0.72298 cur_best_std=0.00180\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.6000000000000001, 'learning_rate': 0.1, 'max_depth': 16, 'min_child_weight': 10, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.057, 'reg_lambda': 0.064, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 247\n",
      "5-fold of Xgboost F1: 0.72340 +/- 0.00193\n",
      "\n",
      "Xgboost objective call #32 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.65, 'learning_rate': 0.1, 'max_depth': 16, 'min_child_weight': 10, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.057, 'reg_lambda': 0.05, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal n_estimators : 182\n",
      "5-fold of Xgboost F1: 0.72215 +/- 0.00177\n",
      "\n",
      "Xgboost objective call #33 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.6000000000000001, 'learning_rate': 0.1, 'max_depth': 16, 'min_child_weight': 10, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.07, 'reg_lambda': 0.049, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 226\n",
      "5-fold of Xgboost F1: 0.72241 +/- 0.00300\n",
      "\n",
      "Xgboost objective call #34 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.8, 'learning_rate': 0.1, 'max_depth': 16, 'min_child_weight': 10, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.088, 'reg_lambda': 0.067, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 201\n",
      "5-fold of Xgboost F1: 0.72298 +/- 0.00203\n",
      "\n",
      "Xgboost objective call #35 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.75, 'learning_rate': 0.1, 'max_depth': 16, 'min_child_weight': 10, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.056, 'reg_lambda': 0.089, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 160\n",
      "5-fold of Xgboost F1: 0.72223 +/- 0.00198\n",
      "\n",
      "Xgboost objective call #36 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 17, 'min_child_weight': 11, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.04, 'reg_lambda': 0.078, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 152\n",
      "5-fold of Xgboost F1: 0.72264 +/- 0.00205\n",
      "\n",
      "Xgboost objective call #37 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.4, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 9, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.065, 'reg_lambda': 0.018000000000000002, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 249\n",
      "5-fold of Xgboost F1: 0.72240 +/- 0.00157\n",
      "\n",
      "Xgboost objective call #38 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 0.8, 'gamma': 0.8500000000000001, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.053, 'reg_lambda': 0.059000000000000004, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 316\n",
      "5-fold of Xgboost F1: 0.72152 +/- 0.00217\n",
      "\n",
      "Xgboost objective call #39 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.6000000000000001, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 3.1500000000000004, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.046, 'reg_lambda': 0.091, 'seed': 7, 'silent': 0, 'subsample': 0.8, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 618\n",
      "5-fold of Xgboost F1: 0.72031 +/- 0.00183\n",
      "\n",
      "Xgboost objective call #40 cur_best_score=0.72340 cur_best_std=0.00193\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.097, 'reg_lambda': 0.069, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 227\n",
      "5-fold of Xgboost F1: 0.72345 +/- 0.00165\n",
      "\n",
      "Xgboost objective call #41 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 1.0, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.091, 'reg_lambda': 0.082, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 328\n",
      "5-fold of Xgboost F1: 0.72297 +/- 0.00241\n",
      "\n",
      "Xgboost objective call #42 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.093, 'reg_lambda': 0.07, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 225\n",
      "5-fold of Xgboost F1: 0.72167 +/- 0.00175\n",
      "\n",
      "Xgboost objective call #43 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.084, 'reg_lambda': 0.081, 'seed': 7, 'silent': 0, 'subsample': 0.7000000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 174\n",
      "5-fold of Xgboost F1: 0.72231 +/- 0.00170\n",
      "\n",
      "Xgboost objective call #44 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 0.9, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 2.85, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.098, 'reg_lambda': 0.096, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 315\n",
      "5-fold of Xgboost F1: 0.72080 +/- 0.00233\n",
      "\n",
      "Xgboost objective call #45 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.8500000000000001, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.075, 'reg_lambda': 0.033, 'seed': 7, 'silent': 0, 'subsample': 0.6000000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 201\n",
      "5-fold of Xgboost F1: 0.72050 +/- 0.00133\n",
      "\n",
      "Xgboost objective call #46 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.75, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.07100000000000001, 'reg_lambda': 0.045, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 248\n",
      "5-fold of Xgboost F1: 0.72260 +/- 0.00199\n",
      "\n",
      "Xgboost objective call #47 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.083, 'reg_lambda': 0.06, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 285\n",
      "5-fold of Xgboost F1: 0.72011 +/- 0.00333\n",
      "\n",
      "Xgboost objective call #48 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 3.5, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.037, 'reg_lambda': 0.07, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal n_estimators : 357\n",
      "5-fold of Xgboost F1: 0.71962 +/- 0.00338\n",
      "\n",
      "Xgboost objective call #49 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.9, 'learning_rate': 0.1, 'max_depth': 17, 'min_child_weight': 11, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.08, 'reg_lambda': 0.076, 'seed': 7, 'silent': 0, 'subsample': 0.8, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 155\n",
      "5-fold of Xgboost F1: 0.72253 +/- 0.00256\n",
      "\n",
      "Xgboost objective call #50 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.8, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 2.4000000000000004, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.061, 'reg_lambda': 0.092, 'seed': 7, 'silent': 0, 'subsample': 0.6000000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 283\n",
      "5-fold of Xgboost F1: 0.71927 +/- 0.00263\n",
      "\n",
      "Xgboost objective call #51 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.75, 'gamma': 1.0, 'learning_rate': 0.1, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.029, 'reg_lambda': 0.04, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 178\n",
      "5-fold of Xgboost F1: 0.72148 +/- 0.00364\n",
      "\n",
      "Xgboost objective call #52 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.25, 'learning_rate': 0.1, 'max_depth': 16, 'min_child_weight': 10, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.094, 'reg_lambda': 0.054, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 203\n",
      "5-fold of Xgboost F1: 0.72228 +/- 0.00263\n",
      "\n",
      "Xgboost objective call #53 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 0.05, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.049, 'reg_lambda': 0.084, 'seed': 7, 'silent': 0, 'subsample': 0.9500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 231\n",
      "5-fold of Xgboost F1: 0.72314 +/- 0.00203\n",
      "\n",
      "Xgboost objective call #54 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.35000000000000003, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 2.75, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.08700000000000001, 'reg_lambda': 0.066, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 630\n",
      "5-fold of Xgboost F1: 0.72047 +/- 0.00239\n",
      "\n",
      "Xgboost objective call #55 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.062, 'reg_lambda': 0.047, 'seed': 7, 'silent': 0, 'subsample': 0.75, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 258\n",
      "5-fold of Xgboost F1: 0.72114 +/- 0.00251\n",
      "\n",
      "Xgboost objective call #56 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.8, 'gamma': 0.45, 'learning_rate': 0.1, 'max_depth': 16, 'min_child_weight': 10, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.017, 'reg_lambda': 0.076, 'seed': 7, 'silent': 0, 'subsample': 0.8500000000000001, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 183\n",
      "5-fold of Xgboost F1: 0.72214 +/- 0.00247\n",
      "\n",
      "Xgboost objective call #57 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.55, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 2.5, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.098, 'reg_lambda': 0.06, 'seed': 7, 'silent': 0, 'subsample': 0.8, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 436\n",
      "5-fold of Xgboost F1: 0.72127 +/- 0.00333\n",
      "\n",
      "Xgboost objective call #58 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.9500000000000001, 'gamma': 0.6000000000000001, 'learning_rate': 0.1, 'max_depth': 14, 'min_child_weight': 8, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.07100000000000001, 'reg_lambda': 0.04, 'seed': 7, 'silent': 0, 'subsample': 0.65, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 252\n",
      "5-fold of Xgboost F1: 0.72149 +/- 0.00291\n",
      "\n",
      "Xgboost objective call #60 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.8500000000000001, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.055, 'reg_lambda': 0.1, 'seed': 7, 'silent': 0, 'subsample': 0.9, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n",
      "Optimal n_estimators : 274\n",
      "5-fold of Xgboost F1: 0.72163 +/- 0.00226\n",
      "\n",
      "Xgboost objective call #61 cur_best_score=0.72345 cur_best_std=0.00165\n",
      "{'colsample_bytree': 0.75, 'gamma': 0.9, 'learning_rate': 0.1, 'max_depth': 17, 'min_child_weight': 11, 'n_estimators': 1000, 'n_gpus': -1, 'num_class': 4, 'objective': 'multi:softmax', 'reg_alpha': 0.044, 'reg_lambda': 0.053, 'seed': 7, 'silent': 0, 'subsample': 1.0, 'tree_method': 'gpu_hist'}\n",
      "===============================================\n",
      "Find the n_estimators\n"
     ]
    }
   ],
   "source": [
    "best = fmin(xgb_classifier, param_space, algo = tpe.suggest, max_evals=100,trials=trials)\n",
    "print ('best:')\n",
    "print (best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
